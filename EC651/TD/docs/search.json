[
  {
    "objectID": "TD3.html",
    "href": "TD3.html",
    "title": "TD3 : Régression non linéaire",
    "section": "",
    "text": "Exercice 1\nOn considère le jeu de données azote_ble.csv disponible  ici .\nOn a recensé ici le rendement (en T/ha) de 92 champs de blés en fonction de la dose d’azote apportée (en kg/ha).\n\nImporter les données dans R, et en faire un bref résumé statistique.\nUn modèle linéaire semble-t-il adapté afin d’expliquer le rendement des champs ?\nOn se propose de modéliser le rendement des champs par un modèle polynomial de degré 3 :\n\n\\[ Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 +\\beta_4X^4+ \\varepsilon\\] où :\n\n\\(X\\) désigne la dose d’azote apportée (en kg/ha);\n\\(Y\\) désigne le rendement du champ (en T/ha);\n\\(\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)\\) désigne un bruit gausssien.\n\nModifier le jeu de données initial afin de faire apparaître les variables \\(X^2\\), \\(X^3\\) et \\(X^4\\).\n\nÀ l’aide de la fonction lm(), ajuster un modèle polynomial aux données.\nQuel est le pourcentage de variance expliquée par le modèle ? Certains coefficients semblent-ils non significatifs ?\nEffectuer un ou plusieurs tests de modèles emboîtés afin de déterminer les coefficients significativement non nuls du modèle. Quel modèle est finalement retenu ?\nTracer le nuage de points représentant les données, et y ajouter les différents intervalles de confiance au niveau 95% pour les prédictions faites par le modèle.\n\n\n\nExercice 2\nOn étudie dans cet exercice l’espérance de vie moyenne dans un pays en fonction de sa population et de son PIB par habitant. On dispose pour cela d’un jeu de données (disponible  ici ) libre de droits issu de la banque mondiale, et disponible sur Gapminder.org, CCBY License.\nOn trouvera dans ce jeu de données pour 142 pays en 2007 :\n\nle PIB par habitant;\nla population du pays;\nle continent du pays;\nl’espérance de vie dans le pays.\n\n\nImporter les données dans R et résumer brièvement les données.\nAjuster un modèle linéaire permettant d’expliquer l’espérance de vie dans un pays en fonction des autres variables. Ecrire mathématiquement ce modèle.\nQuel le pourcentage de variance expliquée par ce modèle ?\nRé-ajuster le modèle afin de ne conserver que les coefficients significativement non nuls.\nUn modèle linéaire n’est pas tout à fait adapté ici. On va utiliser un modèle non linéaire en utilisant une transformation logarithmique sur les données de PIB par habitant.\n\n\nEcrire mathématiquement le modèle considéré.\nCréer une nouvelle variable donnant le logarithme du PIB par habitant.\nReprésenter brièvement les nouvelles données obtenues.\nA l’aide de la fonction lm() ajuster le modèle envisagé aux données.\nRé-ajuster le modèle afin de ne conserver que les coefficients significativement non nuls.\n\n\nOn souhaite dorénavant comparer les deux modèles construits.\n\n\nDans un premier temps, comparer les coefficients de détermination \\(R^2\\) et \\(R_a^2\\).\nOn compare ensuite les critères \\(AIC\\) (Akaike Information Criterion) des deux modèles : \\[AIC = 2p-2\\ln(L)\\] où\n\n\n\\(p\\) désigne le nombre de paramètres à estimer dans le modèle;\n\\(L\\) désigne la vraisemblance du modèle.\n\nUn tel critère vise à pénaliser les modèles ayant trop de paramètres à estimer. Il favorise donc les modèles parcimonieux en sélectionnant le modèle avec le critère \\(AIC\\) le plus faible.\nSélectionner le modèle ayant le meilleur critère \\(AIC\\) à l’aide de la fonction AIC().\n\nOn compare dorénavant les critères \\(BIC\\) (Bayesian Information Criterion) des modèles : \\[BIC = p\\ln(n) -2\\ln(L)\\] où \\(n\\) désigne le nombre d’observations. Une nouvelle fois, le but est de choisir un modèle parcimonieux en sélectionnant le critère \\(BIC\\) le plus faible. Comparé au critère \\(AIC\\), le critère \\(BIC\\) pénalise plus fortement les modèles avec beaucoup de paramètres à estimer.\n\nSélectionner le modèle ayant le meilleur critère \\(BIC\\), à l’aide de la fonction BIC().\n\nEnfin, on compare les performances prédictives des modèles. Pour ce faire, on va estimer le risque quadratique des deux modèles par validation croisée 10 blocs (voir TD2).\n\nSélectionner le modèles semblant avoir la meilleure performance prédictive.",
    "crumbs": [
      "TD3 : Régression non linéaire"
    ]
  },
  {
    "objectID": "TD1.html",
    "href": "TD1.html",
    "title": "TD1 : Régression linéaire simple",
    "section": "",
    "text": "Exercice 1\nOn considère le jeu de données tomato_sauce.csv disponible  ici .\nLes données recueillies portent sur des mesures effectuées sur un site de production de sauce à base de tomate.\nLa variable \\(Y\\) à expliquer, notée rdt, est une réponse liée au rendement de production (% d’extrait de tomate dans la sauce).\nLa variable explicative \\(X\\), notée ratioMP, est relative à la qualité du lot de matières premières (% de solides insolubles dans l’eau par rapport à la quantité de solide totale).\n24 observations ont été réalisées sur une série d’ordres de production consécutifs\n\nImporter les données dans R, et en dresser un rapide résumé statistique.\n\n\n\nVoir le code\n\n\ntomato_sauce &lt;- read.csv(\"tomato_sauce.csv\",sep=\";\",row.names=1)\nsummary(tomato_sauce)\n\n    ratioMP           rdt       \n Min.   :10.71   Min.   :30.20  \n 1st Qu.:12.67   1st Qu.:35.88  \n Median :13.70   Median :39.10  \n Mean   :13.78   Mean   :39.73  \n 3rd Qu.:14.82   3rd Qu.:43.38  \n Max.   :18.22   Max.   :51.00  \n\n\n\n\nRéaliser les boxplots et histogrammes des différentes variables. Commenter.\n\n\n\nVoir le code\n\n\nlibrary(ggplot2)\n\n# Boxplots\nggplot(tomato_sauce) + aes(x=\"\",y=ratioMP)+\n  geom_boxplot(width=0.1)+\n  theme_minimal()+\n  labs(title=\"Distribution de la variable ratioMP\",x=\"\")\n\n\n\n\n\n\n\n# On remarque une valeur anormalement grande\nggplot(tomato_sauce) + aes(x=\"\",y=rdt)+\n  geom_boxplot(width=0.1)+\n  theme_minimal()+\n  labs(title=\"Distribution de la variable rdt\",x=\"\")\n\n\n\n\n\n\n\n# Rien à signaler\n\n# Histogrammes\nn &lt;- nrow(tomato_sauce) # nombre d'observations\nn_class &lt;- ceiling(1+3.3*log10(n)) #nombre de classes (Formule de Sturges)\n\nggplot(tomato_sauce)+ aes(x=ratioMP)+\n  geom_histogram(fill=\"skyblue\",color=\"grey40\",bins=n_class)+\n  theme_minimal()+\n  labs(title=\"Distribution de la variable ratioMP\",y=\"Effectifs\")\n\n\n\n\n\n\n\n# Il y a un cerrtain nombre de valeurs très basses, les autres étant globalement regroupées autour de la moyenne\nggplot(tomato_sauce)+ aes(x=rdt)+\n  geom_histogram(fill=\"skyblue\",color=\"grey40\",bins=n_class)+\n  theme_minimal()+\n  labs(title=\"Distribution de la variable rdt\",y=\"Effectifs\")\n\n\n\n\n\n\n\n# Les données semblent regroupées en 2 paquets : un autour de 37, l'autre, plus petit, autour de 45\n\n\n\nTracer le nuage de points associé aux données, puis calculer le coefficient de corrélation linéaire entre les deux variables (rappeler la définition de ce dernier).\n\n\n\nCommentaire\n\nPour deux séries d’observations \\((x_i)_{1\\leqslant i \\leqslant n}\\) et \\((y_i)_{1\\leqslant i \\leqslant n}\\), le coefficient de corrélation est donné par \\[\\rho = \\dfrac{\\sum_{i=1}^n (x_i -\\overline{x})(y_i-\\overline{y})}{\\sqrt{\\sum_{i=1}^n (x_i-\\overline{x})^2}\\times \\sqrt{\\sum_{i=1}^n (y_i-\\overline{y})^2}}\\]\n\n\n\nVoir le code\n\n\nggplot(tomato_sauce) + aes(x=ratioMP,y=rdt)+\n  geom_point(color=\"tomato\")+\n  theme_minimal()+\n  labs(title=\"Nuage de points rdt VS ratioMP\")\n\n\n\n\n\n\n\ncor.test(x=tomato_sauce$ratioMP,y=tomato_sauce$rdt)\n\n\n    Pearson's product-moment correlation\n\ndata:  tomato_sauce$ratioMP and tomato_sauce$rdt\nt = -18.718, df = 22, p-value = 5.293e-15\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9871402 -0.9308572\nsample estimates:\n       cor \n-0.9700104 \n\n\n\nCelui-ci est-il significativement non nul ? Un modèle linéaire semble-t-il adapté aux données ? Ecrire mathématiquement ce modèle.\n\n\nRéponse\n\nLe test statistique réalisé nous renvoie une \\(p\\)-value inférieure à 0.05 (elle est égale à \\(5.293\\times 10^{-15}\\)). On rejette donc l’hypothèse nulle comme quoi les deux séries sont non corrélées. En d’autres termes, le coefficient de corrélation est siginificativement non nul. Un modèle linéaire semble alors parfaitement adapté aux données (tendance linéaire sur le nuage de points + coefficient de corrélation significativement non nul). Celui-ci s’écrit \\[ rdt_i = \\beta_0 + \\beta_1 ratioMP_i + \\varepsilon_i, \\quad 1 \\leqslant i  \\leqslant n,\\] où les \\(\\varepsilon_i\\) sont i.i.d. de loi \\(\\mathcal{N}(0,\\sigma^2)\\).\n\n\nÀ l’aide de la fonction lm(), ajsuter un modèle linéaire aux données. En faire un résumé rapide avec la fonction summary().\n\n\n\nVoir le code\n\n\nlm_sauce &lt;- lm(data=tomato_sauce,formula = rdt~.)\nsummary(lm_sauce)\n\n\nCall:\nlm(formula = rdt ~ ., data = tomato_sauce)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.5871 -0.9040 -0.1434  1.0381  3.1522 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  76.1934     1.9657   38.76  &lt; 2e-16 ***\nratioMP      -2.6467     0.1414  -18.72 5.29e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.288 on 22 degrees of freedom\nMultiple R-squared:  0.9409,    Adjusted R-squared:  0.9382 \nF-statistic: 350.4 on 1 and 22 DF,  p-value: 5.293e-15\n\n\n\n\nDonner les valeurs estimées des coefficients du modèle, ainsi qu’un intervalle de confiance à 95% de ces coefficients avec la fonction confint(). Ceux-ci sont-ils significativement non nuls ? Préciser la statistique de test utilisée ici.\n\n\n\nRéponse\n\nOn a les estimations \\[\\hat{\\beta}_0 \\approx 76.1934 \\quad \\text{et} \\quad \\hat{\\beta}_1 \\approx -2.6467.\\] Ceux-ci sont significativement non nuls (présence de 3 étoiles dans le résumé). La statistique de test utilisée ici est, pour \\(i \\in \\{0,1\\}\\) \\[t_i = \\dfrac{\\hat{\\beta}_i}{\\hat{\\sigma}_i} \\] qui suit la loi de Student \\(\\mathcal{T}_{n-2}\\) sous l’hypothèse nulle \\(H_0 : \\beta_i=0\\). Les intervalles de confiance des coefficients sont donnés par le code ci-dessous.\n\n\n\nVoir le code\n\n\nconfint(lm_sauce)\n\n                2.5 %    97.5 %\n(Intercept) 72.116805 80.270061\nratioMP     -2.939885 -2.353422\n\n\n\n\nQuelle est la proportion de variance expliquée par le modèle ? Rappeler la définition de l’indicateur statistique utilisé.\n\n\n\nRéponse\n\nOn utilise le coefficient de déterminations \\(R^2\\) \\[ R^2 = \\dfrac{SCE}{SCT} = \\dfrac{\\sum_{i=1}^n (\\hat{y}_i-\\overline{y})^2}{\\sum_{i=1}^n (y_i-\\overline{y})^2}\\] où les \\(\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_i\\) sont les valeurs ajustées par le modèle. Ici, on a \\(R^2 \\approx 0.9409\\), ce qui signifie que le modèle explique 94,09% de la variance. Il est donc extrêmement bien adapté aux données.\n\n\nUtiliser la fonction geom_smooth() du package ggplot2 afin de tracer la droite de régression linéaire ajustée aux données.\n\nL’intervalle de confiance à 95% tracé par cette fonction est celui de la valeur \\(\\hat{\\beta}_0 + \\hat{\\beta}_1 x\\). Il s’agit en fait de l’intervalle de confiance pour la valeur moyenne de la variable réponse \\(y\\).\n\n\nVoir le code\n\n\nggplot(tomato_sauce) + aes(x=ratioMP,y=rdt)+\n  geom_point(color=\"tomato\")+\n  geom_smooth(method=\"lm\",color=\"tomato\",linetype=\"dashed\",lwd=0.5,fill=\"tomato\",alpha=0.2)+\n  theme_minimal()+\n  labs(title = \"rdt VS ratioMP\")\n\n\n\n\n\n\n\n\n\n\nOn souhaite à présent rajouter l’intervalle de confiance pour les prévisions faites par le modèle. Celui-ci est différent de l’intervalle tracé par la fonction geom_smooth(). Il prend notamment en compte la dispersion liée au bruit gaussien du modèle.\n\n\nA l’aide de la fonction predict() récupérer les bornes inférieures et supérieures des prévisions associées aux observations du jeu de données. On stockera ces valeurs dans le data-frame initial avec pour noms de variables pred_lwr et pred_upr.\nRajouter, à l’aide de la fonction geom_line(), ces bornes sur le graphique réalisé jusqu’à présent.\n\n\n\nVoir le code\n\n\nlibrary(tidyverse)\npred &lt;- predict(lm_sauce,newdata = tomato_sauce,interval=\"prediction\")\n\ntomato_sauce &lt;- tomato_sauce %&gt;%\n  mutate(pred_lwr = pred[,2],\n         pred_upr = pred[,3])\n\nggplot(tomato_sauce) + aes(x=ratioMP,y=rdt)+\n  geom_point(color=\"tomato\")+\n  geom_smooth(method=\"lm\",linetype=\"dashed\",lwd=0.5,color=\"tomato\",alpha=0.2,\n              aes(fill=\"Intervalle de confiance pour la valeur moyenne (95%)\"))+\n  scale_fill_manual(values=\"tomato\")+\n  theme_minimal()+\n  labs(title = \"rdt VS ratioMP\")+\n  geom_line(aes(y=pred_lwr,linetype=\"Intervalle de confiance pour les prévisions (95%)\"))+\n  geom_line(aes(y=pred_upr,linetype=\"Intervalle de confiance pour les prévisions (95%)\"))+\n  scale_linetype_manual(values=\"dotted\")+\n  theme(legend.title = element_blank(),\n        legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\nExercice 2\nOn s’intéresse ici à l’équilibre des saveurs dans différents cidres.\n90 cidres bruts ont été évalués par un jury sensoriel formé de 24 juges (échelle de notation de 1 à 10, calcul des notes moyennes), selon différents critères :\n\nSaveur sucrée;\nSaveur Acide;\nSaveur amère;\nSaveur astringente\n\nOn étudie plus précisément la relation entre la saveur astringente (variable réponse) des cidres et leur saveur amère (variable explicative).\n\nImporter le jeu de données dans R (disponible  ici ), et en dresser un rapide résumé statistique.\n\n\n\nVoir le code\n\n\ncidre &lt;- read.csv(\"cidre.csv\",row.names = 1)\nsummary(cidre)\n\n    S.Sucree        S.Acide         S.Amere      S.Astringente   \n Min.   :3.444   Min.   :2.107   Min.   :2.143   Min.   :0.7143  \n 1st Qu.:4.580   1st Qu.:3.625   1st Qu.:3.286   1st Qu.:1.4732  \n Median :5.250   Median :4.089   Median :3.964   Median :2.0000  \n Mean   :5.169   Mean   :4.181   Mean   :4.274   Mean   :2.0561  \n 3rd Qu.:5.670   3rd Qu.:4.643   3rd Qu.:5.268   3rd Qu.:2.4286  \n Max.   :7.036   Max.   :6.536   Max.   :7.857   Max.   :4.6786  \n                                                 NA's   :4       \n\nsum(is.na(cidre))\n\n[1] 4\n\n# Attention, il y a 4 valeurs manquantes pour la saveur Astringente...\n\n\n\nReprésenter graphiquement la distribution des différentes variables du jeu de données par la méthode de votre choix.\n\n\n\nVoir le code\n\n\n# On se propose ici de faire des boxplots\nggplot(cidre) + aes(x=\"\",y=S.Sucree)+\n  geom_boxplot(width=0.1)+\n  theme_minimal()+\n  labs(x=\"\",\n       y=\"Saveur sucrée\",\n       title = \"Distribution des notes pour la saveur sucrée\")\n\n\n\n\n\n\n\nggplot(cidre) + aes(x=\"\",y=S.Acide)+\n  geom_boxplot(width=0.1)+\n  theme_minimal()+\n  labs(x=\"\",\n       y=\"Saveur sucrée\",\n       title = \"Distribution des notes pour la saveur acide\")\n\n\n\n\n\n\n\nggplot(cidre) + aes(x=\"\",y=S.Amere)+\n  geom_boxplot(width=0.1)+\n  theme_minimal()+\n  labs(x=\"\",\n       y=\"Saveur sucrée\",\n       title = \"Distribution des notes pour la saveur amère\")\n\n\n\n\n\n\n\nggplot(cidre) + aes(x=\"\",y=S.Astringente)+\n  geom_boxplot(width=0.1)+\n  theme_minimal()+\n  labs(x=\"\",\n       y=\"Saveur sucrée\",\n       title = \"Distribution des notes pour la saveur astringente\")\n\n\n\n\n\n\n\n# On remarque quelques outliers pour les saveurs acide et astringente\n\n\n\nCombien de données manquantes le jeu de données comporte-t-il ?\n\n\n\nRéponse\n\nComme indiqué plus haut, il y en a quatre.\n\n\nOn souhaite imputer ces valeurs manquantes via un modèle linéaire simple reliant la saveur astringente (variable réponse) des cidre et leur saveur amère (variable explicative).\n\nUn tel modèle vous semble-t-il adapté ?\n\n\nRéponse\n\nOn va réaliser un nuage de points de ces deux variables, et calculer leur coefficient de corrélation.\n\nggplot(cidre) + aes(x=S.Amere,y=S.Astringente)+\n  geom_point(color=\"tomato\")+\n  theme_minimal()+\n  labs(title=\"Saveur astringente en fonction de la saveur amère\",\n       x=\"Note de saveur amère\",\n       y=\"Note de saveur astringente\")\n\n\n\n\n\n\n\ncor.test(x=cidre$S.Amere,y=cidre$S.Astringente)\n\n\n    Pearson's product-moment correlation\n\ndata:  cidre$S.Amere and cidre$S.Astringente\nt = 13.583, df = 84, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7485333 0.8853255\nsample estimates:\n     cor \n0.828942 \n\n\nEtant donné la forme du nuage de points et la significativité du coefficient de corrélation (\\(p\\)-value inférieure à \\(2.2\\times 10^{-16}\\) dans le test de nullité), un modèle linéaire semble parfaiement adapté aux données.\n\n\nAjuster un modèle linéaire donnant la saveur astringente en fonction de la saveur amère. Quel est le pourcentage de variance expliquée par ce modèle ?\n\n\n\nVoir le code\n\n\nlm_cidre &lt;- lm(data=cidre,formula = S.Astringente~S.Amere)\nsummary(lm_cidre)\n\n\nCall:\nlm(formula = S.Astringente ~ S.Amere, data = cidre)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.14284 -0.32774 -0.05057  0.27225  1.60204 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.14678    0.16938  -0.867    0.389    \nS.Amere      0.50964    0.03752  13.583   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4532 on 84 degrees of freedom\n  (4 observations effacées parce que manquantes)\nMultiple R-squared:  0.6871,    Adjusted R-squared:  0.6834 \nF-statistic: 184.5 on 1 and 84 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\nRéponse\n\nLe pourcentage de variance expliquée par ce modèle est de 68,71%.\n\n\nSur un graphique, représenter :\n\n\nle nuage de points donnant la saveur astringente des cidres en fonction de leur saveur amère;\nla droite de régression linéaire donnée par le modèle utilisé;\nles différents intervalles de confiance au niveau 95% pour les prévisions faites par le modèle.\n\n\n\nVoir le code\n\n\npred &lt;- predict(lm_cidre,newdata = cidre,interval=\"prediction\")\ncidre &lt;- cidre %&gt;%\n  mutate(pred_lwr=pred[,2],\n         pred_upr=pred[,3])\n\nggplot(cidre)+aes(x=S.Amere,y=S.Astringente)+\n  geom_point(color=\"tomato\")+\n  geom_smooth(method=\"lm\",color=\"tomato\",lwd=0.5,linetype=\"dashed\",alpha=0.2,\n              aes(fill=\"Intervalle de confiance pour la valeur moyenne (95%)\"))+\n  scale_fill_manual(values=\"tomato\")+\n  geom_line(aes(y=pred_lwr,linetype = \"Intervalle de confiance pour les prévisions (95%)\"))+\n  geom_line(aes(y=pred_upr,linetype = \"Intervalle de confiance pour les prévisions (95%)\"))+\n  scale_linetype_manual(values=\"dotted\")+\n  theme_minimal()+\n  labs(title = \"Saveur astringente en fonction de la saveur amère\",\n       x=\"Note de aveur amère\",\n       y=\"Note de saveur astringente\")+\n  theme(legend.position = \"bottom\",\n        legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\nImputer enfin les valeurs manquantes, et donner leur intervalle de confiance au niveau 95%.\n\n\n\nVoir le code\n\n\nvalues_to_impute &lt;- cidre %&gt;%\n  filter(is.na(S.Astringente))\nimputed_values &lt;- predict(lm_cidre,newdata = values_to_impute,interval = \"prediction\")\nimputed_values\n\n       fit       lwr      upr\n1 1.363927 0.4517479 2.276105\n2 1.491336 0.5810406 2.401631\n3 1.855363 0.9483536 2.762371\n4 1.309323 0.3962213 2.222424",
    "crumbs": [
      "TD1 : Régression linéaire simple"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EC651 et 56/53 : Modélisation statistique (Régression linéaire)",
    "section": "",
    "text": "Avant-Propos\nCe notebook contient les exercices liés à la première partie du cours de modélisation statistique, concernant la régression linéaire.\nVous trouverez, sur la barre de navigation à gauche, le menu vous permettant d’accéder aux différents TDs.\nVous trouverez ci-dessous des liens utiles pour ce cours et ces TDS :\n\nLes slides de cours;\nLe polycopié d’Arnaud Guyader;\nLe lien vers le site du livre R pour la statistique et la science des données, sous la direction de F.Husson.",
    "crumbs": [
      "Avant-Propos"
    ]
  },
  {
    "objectID": "TD2.html",
    "href": "TD2.html",
    "title": "TD2 : Régression linéaire multiple",
    "section": "",
    "text": "Exercice 1\nOn considère un échantillon de 500 produits anti-âge disponible  ici .\nLe jeu de données consiste en 6 variables :\n\nproduct_type,\nviscosity en mPa.s,\npH,\ndensity en g/cm\\(^3\\),\nsurface_tension en mN/m,\nuser_rating, correspondant à une note moyenne donnée par les consommateurs (entre 1 et 5).\n\nOn cherche à expliquer la note donnée par les consommateurs en fonction des autres variables.\n\nImporter les données dans R et effectuer un rapide résumé statistique.\n\n\n\nVoir le code\n\n\ncosmetics &lt;- read.csv(\"cosmetics.csv\",row.names=1)\nlibrary(tidyverse)\ncosmetics &lt;- cosmetics %&gt;%\n  mutate(product_type=as.factor(product_type)) # On met cette variable en facteur\nsummary(cosmetics)\n\n product_type   viscosity            pH           density       surface_tension\n cream :122   Min.   : 534.9   Min.   :4.620   Min.   :0.9180   Min.   :26.20  \n gel   :122   1st Qu.: 893.0   1st Qu.:5.515   1st Qu.:0.9577   1st Qu.:33.10  \n lotion:108   Median :1290.8   Median :5.900   Median :0.9950   Median :36.20  \n serum :148   Mean   :1711.8   Mean   :5.881   Mean   :0.9905   Mean   :37.30  \n              3rd Qu.:1826.4   3rd Qu.:6.240   3rd Qu.:1.0180   3rd Qu.:41.23  \n              Max.   :4104.0   Max.   :7.020   Max.   :1.0590   Max.   :53.30  \n  user_rating   \n Min.   :2.490  \n 1st Qu.:3.170  \n Median :3.415  \n Mean   :3.481  \n 3rd Qu.:3.763  \n Max.   :4.760  \n\n\n\n\nReprésenter graphiquement les liens pouvant exister entre la variable user_rating et les autres.\n\n\n\nVoir le code\n\n\nlibrary(GGally)\n\nggpairs(cosmetics[,2:6])\n\n\n\n\n\n\n\n\n\n\n\nCommentaire\n\nBien que les corrélations calculées entre les différentes variables soient significativement non nuls, les nuages de points ne montrent pas de tendance particulière, si ce n’est entre les variables user_rating et surface_tension. On remarque toutefois des clusters sur certains nuages de points, notamment pour la variable viscosity, montrant l’impact de la variable catégorielle product_type, indiquant si le produit est une crème, un gel, etc…\n\n\nUn modèle linéaire semble-t-il adapté pour prédire la note donnée par les consommateurs ? Ecrire mathématiquement ce modèle.\n\n\n\nRéponse\n\nD’après la significativité des coefficients de corrélation, on peut penser qu’un modèle linéaire est adapté aux données. On fera toutefois attention au fait que les variables explicatives sont parfois fortement corrélées entre elles. Etant donné la présence d’une variable qualitative (product_type), celui-ci s’écrit un peu différemment. On note :\n\n\\(Y\\) la variable réponse user_rating, (observations \\(y_1,\\ldots,y_n\\));\n\\(X_1\\) la variable product_type, (observations \\(x_{1,1},\\ldots,x_{n,1}\\));\n\\(X_2\\) la variable viscosity, (observations \\(x_{1,2},\\ldots,x_{n,2}\\));\n\\(X_3\\) la variable pH, (observations \\(x_{1,3},\\ldots,x_{n,3}\\));\n\\(X_4\\) la variable density, (observations \\(x_{1,4},\\ldots,x_{n,4}\\));\n\\(X_5\\) la variable surface_tension, (observations \\(x_{1,5},\\ldots,x_{n,5}\\)).\n\nOn a alors pour tout \\(i \\in \\{1,\\ldots,n\\}\\) \\[y_i = \\beta_0 + \\beta_1^{gel} \\mathbf{1}_{gel}(x_{i,1}) + \\beta_1^{lotion} \\mathbf{1}_{lotion}(x_i,1) +\\beta_1^{serum} \\mathbf{1}_{serum}(x_{i,1}) + \\beta_2 x_{i,2} + \\beta_3 x_{i,3} +\\beta_4 x_{i,4} + \\beta_5 x_{i,5} + \\varepsilon_i\\] où les \\(\\varepsilon_i\\) son i.i.d. de loi \\(\\mathcal{N}(0,\\sigma^2)\\).\nRemarque : Le modèle ne contient ici pas de coefficient \\(\\beta_1^{cream}\\) pour des raisons d’identifiabilité. En d’autres termes, si on intégrait ce coeffcient dans le modèle, différentes valeurs des coefficients aboutiraient aux mêmes valeurs réponses, ce qui poseraient un souci quant à la bonne définition du problème.\n\n\nAjuster un modèle linéaire aux données, permettant d’expliquer user_rating en fonction des autres variables.\n\n\n\nVoir le code\n\n\nlm_cosmetics &lt;- lm(data=cosmetics,formula = user_rating~.)\nsummary(lm_cosmetics)\n\n\nCall:\nlm(formula = user_rating ~ ., data = cosmetics)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.80811 -0.20967  0.01328  0.19511  0.93520 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         3.037e+00  9.844e-01   3.085  0.00215 ** \nproduct_typegel     1.238e-01  1.965e-01   0.630  0.52905    \nproduct_typelotion  4.285e-02  1.621e-01   0.264  0.79161    \nproduct_typeserum   9.843e-02  2.168e-01   0.454  0.65001    \nviscosity           2.848e-04  7.241e-05   3.933  9.6e-05 ***\npH                 -1.651e-01  6.498e-02  -2.542  0.01134 *  \ndensity             6.947e-01  8.555e-01   0.812  0.41714    \nsurface_tension     4.606e-03  5.795e-03   0.795  0.42706    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2916 on 492 degrees of freedom\nMultiple R-squared:  0.5926,    Adjusted R-squared:  0.5868 \nF-statistic: 102.2 on 7 and 492 DF,  p-value: &lt; 2.2e-16\n\n\n\nQuel est le pourcentage de variance expliquée par le modèle ?\nQuelles variables ne semblent pas expliquer la note donnée par les consommateurs ?\n\n\nRéponse\n\n\nLe coefficient \\(R^2\\) calculé est de 0.5926. Le modèle explique donc 59,26% de la variance.\nLes variables ayant un coefficient non significatif sont les suivantes :\n\nproduct_type;\ndensity;\nsurface_tension.\n\n\nElles ne semblent donc pas expliquer la note donnée par les consommateurs.\n\n\nÀ l’aide de la fonction anova(), réaliser un test de modèles emboîtés afin de déterminer les variables intervenant réellement dans le modèle. Ecrire les hypothèses envisagées dans ce test.\n\n\n\nRéponse\n\nD’après le résumé statistique effectué précédemment, on envisage le test \\[ H_0 : \\beta_1^{gel}=\\beta_1^{lotion} = \\beta_1^{serum}=\\beta_4=\\beta_5=0 \\quad \\text{contre} \\quad H_1 : \\text{l'un de ces coeffcients est non nul.} \\] On rappelle que la statistique de test utilisée ici est \\[ F = \\dfrac{n-p}{q} \\times \\dfrac{SCR_0 - SCR}{SCR}, \\] qui suit une loi de Fisher \\(\\mathcal{F}_{n-p}^q\\) sous \\(H_0\\), où\n\n\\(p\\) est le nombre de paramètres à estimer dans le modèle complet;\n\\(q\\) est la différence du nombre de paramètres à estimer entre le modèle complet et le modèle réduit;\n\\(SCR\\) est la somme des carrés résiduelle dans le modèle complet;\n\\(SCR_0\\) est la somme des carrés résiduelle dans le modèle réduit.\n\n\n\n\nVoir le code\n\n\nlm_cosmetics_reduit &lt;- lm(data=cosmetics,formula = user_rating ~ product_type + viscosity + pH)\nanova(lm_cosmetics,lm_cosmetics_reduit)\n\nAnalysis of Variance Table\n\nModel 1: user_rating ~ product_type + viscosity + pH + density + surface_tension\nModel 2: user_rating ~ product_type + viscosity + pH\n  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)\n1    492 41.825                           \n2    494 41.943 -2  -0.11823 0.6954 0.4994\n\n# Avec une p-value de 0.4994, one ne rejette pas l'hypothèse nulle H0.\n\n\n\nOn souhaite maintenant comparer les performances prédictitives des deux modèles utilisés précédemment :\n\n\nle modèle complet, avec toutes les variables;\nle modèle réduit, comprenant uniquement les variables semblant expliquer la note donnée par les consommateurs.\n\nPour ce faire, on dispose de 50 données supplémentaires (disponibles  ici ).\nPrédire, avec les deux modèles, les notes données par les consommateurs pour ces 50 nouveaux produits.\n\n\nVoir le code\n\n\ncosmetics_extra &lt;- read.csv(\"cosmetics_extra.csv\",row.names=1)%&gt;%\n  mutate(product_type=as.factor(product_type))\npred_complet &lt;- predict(lm_cosmetics,newdata = cosmetics_extra)\npred_reduit &lt;- predict(lm_cosmetics_reduit, newdata = cosmetics_extra)\n\n\n\nCalculer, pour chacune des prédictions, l’erreur quadratique moyenne \\(MSE\\) réalisée par chaque modèle : \\[ MSE = \\dfrac{1}{50} \\sum_{i=1}^{50} (y_i - \\hat{y}_i)^2 \\]\n\n\n\nVoir le code\n\n\nMSE_complet &lt;- mean((pred_complet-cosmetics$user_rating)^2)\nMSE_reduit &lt;- mean((pred_reduit-cosmetics$user_rating)^2)\nMSE_complet\n\n[1] 0.3117702\n\nMSE_reduit\n\n[1] 0.3111741\n\n\n\nQuel modèle semble avoir la meileure performance prédictive ? Comparer avec les coefficients de détermination \\(R^2\\) obtenus par chacun des modèles.\n\n\nRéponse\n\nAvec un \\(MSE\\) inférieur, le modèle réduit réalise moins d’erreur sur la prédiction de nouvelles données. Le coefficient de détermination \\(R^2\\) de ce modèle est pourtant plus petit que celui du modèle complet.\n\nsummary(lm_cosmetics_reduit)\n\n\nCall:\nlm(formula = user_rating ~ product_type + viscosity + pH, data = cosmetics)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.82786 -0.21084  0.00943  0.19225  0.93313 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         3.9425852  0.4315259   9.136  &lt; 2e-16 ***\nproduct_typegel     0.0958744  0.1874004   0.512   0.6092    \nproduct_typelotion  0.0253044  0.1573501   0.161   0.8723    \nproduct_typeserum   0.0069341  0.2013920   0.034   0.9725    \nviscosity           0.0002835  0.0000722   3.926 9.87e-05 ***\npH                 -0.1661681  0.0649299  -2.559   0.0108 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2914 on 494 degrees of freedom\nMultiple R-squared:  0.5914,    Adjusted R-squared:  0.5873 \nF-statistic:   143 on 5 and 494 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\nExercice 2\nOn considère ici les données présentées dans les slides de cours sur le rendement de 80 champs de tomates, disponibles  ici .\n\nImporter les données dans R et effectuer un rapide résumé statistique. Représenter par un graphique simple les données.\n\n\n\nVoir le code\n\n\nchamps_tomates &lt;- read.csv(\"champs_tomates.csv\",row.names=1)\nggpairs(champs_tomates)\n\n\n\n\n\n\n\n\n\n\nAjuster un modèle linéaire aux données. Quel est le pourcentage de variance expliquée par le modèle ?\n\n\n\nVoir le code\n\n\nlm_tomates &lt;- lm(data=champs_tomates,formula = Rendement~.)\nsummary(lm_tomates)\n\n\nCall:\nlm(formula = Rendement ~ ., data = champs_tomates)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.249633 -0.046002 -0.000089  0.061775  0.233529 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    2.1283588  0.2857600   7.448 1.42e-10 ***\nEngrais        0.0013818  0.0004776   2.894 0.005001 ** \nIrrigation     0.0082729  0.0040953   2.020 0.046994 *  \nHeures_Travail 0.0021900  0.0031519   0.695 0.489337    \nQualite_Sol    0.0041781  0.0011842   3.528 0.000723 ***\nTemperature    0.0180394  0.0115351   1.564 0.122114    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1016 on 74 degrees of freedom\nMultiple R-squared:  0.3499,    Adjusted R-squared:  0.306 \nF-statistic: 7.965 on 5 and 74 DF,  p-value: 4.767e-06\n\n# Le modèle explique 34,99% de la variance.\n\n\n\nQuels coefficients de la régression ne semblent pas significatifs ? Préciser la statistique de test utilisée.\n\n\n\nRéponse\n\nPour chaque coefficient \\(\\beta_i\\), on effectue le test \\[H_0 : \\beta_i = 0 \\quad \\text{contre} \\quad H_1 : \\beta_i \\neq0.\\] Sous \\(H_0\\), on a \\(t_i = \\dfrac{\\hat{\\beta}_i}{\\hat{\\sigma}_i} \\sim \\mathcal{T}_{n-p}\\), où \\(p\\) est le nombre de paramètres à estimer. On rejette \\(H_0\\) au seuil \\(\\alpha\\) si \\(|t_i| &gt; t_{n-p}(1-\\alpha/2)\\) le quantile d’ordre \\(1-\\alpha/2\\) de la loi \\(\\mathcal{T}_{n-p}\\).\nIci, les coefficients associés aux variables Heures_Travail et Temperature ne sont pas signifcativeùent non nuls.\n\n\nRéaliser un test de modèles emboîtés afin de tester la nullité simultanée de ces coefficients. Quel est la statistique de test utilisée ici ?\n\n\n\nRéponse\n\nOn teste ici \\[H_0 : \\beta_3 = \\beta_5 = 0 \\quad \\text{contre} \\quad H_1: \\beta_3\\neq 0 \\ \\text{ou} \\ \\beta_5 \\neq 0. \\] Sous \\(H_0\\), la statistique de test \\[ F = \\dfrac{n-p}{2}\\times \\dfrac{SCR_0-SCR}{SCR}\\] suit la loi de Fisher \\(\\mathcal{F}_{n-p}^2\\), où\n\n\\(SCR\\) est la somme des carrés résiduelle quand on prend toutes les variables dans le modèle;\n\\(SCR_0\\) est la somme des carrés résiduelles quand on ne prend pas les variables Heures_Travail et Temperature dans le modèle.\n\n\nlm_tomates_reduit &lt;- lm(data=champs_tomates,formula = Rendement~Engrais + Irrigation + Qualite_Sol)\nanova(lm_tomates,lm_tomates_reduit)\n\nAnalysis of Variance Table\n\nModel 1: Rendement ~ Engrais + Irrigation + Heures_Travail + Qualite_Sol + \n    Temperature\nModel 2: Rendement ~ Engrais + Irrigation + Qualite_Sol\n  Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)\n1     74 0.76409                           \n2     76 0.79376 -2 -0.029669 1.4367 0.2443\n\n\nIci, on ne rejette pas l’hypothèse nulle (\\(p\\)-value égale à 0.2443).\n\n\nComme dans l’exercice précédent, on souhaite comparer la capacité prédictive des deux modèles construits.\n\nPour ce faire, on propose d’utiliser une validation croisée 10 blocs. Le principe est de séparer aléatoirement le jeu de données en 10 blocs de 8 observations, et d’ajuster 10 fois le modèle linéaire avec les variables retenues. Pour chacun des 10 ajustements :\n\n9 blocs (72 observations) servent à entraîner le modèle;\n1 bloc (8 observations) sert à prédire les nouvelles valeurs, et calculer le \\(MSE\\) sur 8 valeurs;\non estime enfin le risque quadratique du modèle en calculant la moyenne des 10 \\(MSE\\) calculés.\n\nOn présente ci-dessous un code utilisant le package tidymodels permettant d’effectuer cette validation croisée pour le modèle complet.\n\nlibrary(tidymodels)\nset.seed(42)\n\n# Création des 10 blocs\nfolds &lt;- vfold_cv(data=df_tomato,v = 10) \n\n# Spécification du modèle linéaire utilisé\nlm_spec &lt;- linear_reg(mode=\"regression\",engine=\"lm\")\n\n# Précision du modèle utilisé dans un workflow\nlm_workflow &lt;- workflow() %&gt;% add_model(lm_spec) %&gt;% add_formula(Rendement~.)\n\n# Ajustement du modèle pour chaque bloc\nlm_cv &lt;- lm_workflow %&gt;% fit_resamples(resamples = folds)\n\n# Récupération des métriques d'évaluation obtenues par validation croisée\nmetrics_lm_cv &lt;- collect_metrics(lm_cv)\nmetrics_lm_cv\n\nAdapter ce code au problème de l’exercice, et comparer les performances prédictives du modèle complet et du modèle réduit.\n\n\nRéponse\n\nOn effectue une validation croisée pour chaque modèle. Pour le modèle complet, on a :\n\nlibrary(tidymodels)\nset.seed(42)\n\n# Création des 10 blocs\nfolds &lt;- vfold_cv(data=champs_tomates,v = 10) \n\n# Spécification du modèle linéaire utilisé\nlm_spec &lt;- linear_reg(mode=\"regression\",engine=\"lm\")\n\n# Précision du modèle utilisé dans un workflow\nlm_workflow_complet &lt;- workflow() %&gt;% add_model(lm_spec) %&gt;% add_formula(Rendement~.)\n\n# Ajustement du modèle pour chaque bloc\nlm_cv_complet &lt;- lm_workflow_complet %&gt;% fit_resamples(resamples = folds)\n\n# Récupération des métriques d'évaluation obtenues par validation croisée\nmetrics_lm_cv_complet &lt;- collect_metrics(lm_cv_complet)\n\nEt pour le modèle réduit :\n\n# Précision du modèle utilisé dans un workflow\nlm_workflow_reduit &lt;- workflow() %&gt;% add_model(lm_spec) %&gt;% \n  add_formula(Rendement~Engrais + Irrigation + Qualite_Sol)\n\n# Ajustement du modèle pour chaque bloc\nlm_cv_reduit &lt;- lm_workflow_reduit %&gt;% fit_resamples(resamples = folds)\n\n# Récupération des métriques d'évaluation obtenues par validation croisée\nmetrics_lm_cv_reduit &lt;- collect_metrics(lm_cv_reduit)\n\nOn compare ensuite les \\(RMSE\\), qui sont les racines carrées des \\(MSE\\) définis plus haut.\n\nmetrics_lm_cv_complet\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   0.0990    10  0.0120 pre0_mod0_post0\n2 rsq     standard   0.416     10  0.0783 pre0_mod0_post0\n\nmetrics_lm_cv_reduit\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   0.0983    10  0.0118 pre0_mod0_post0\n2 rsq     standard   0.412     10  0.0807 pre0_mod0_post0\n\n\nLe modèle réduit semble ainsi légèrement plus performant que le modèle complet pour effectuer des pévisions.",
    "crumbs": [
      "TD2 : Régression linéaire multiple"
    ]
  }
]