[
  {
    "objectID": "TD3.html",
    "href": "TD3.html",
    "title": "TD3 : Régression non linéaire",
    "section": "",
    "text": "Exercice 1\nOn considère le jeu de données azote_ble.csv disponible  ici .\nOn a recensé ici le rendement (en T/ha) de 92 champs de blés en fonction de la dose d’azote apportée (en kg/ha).\n\nImporter les données dans R, et en faire un bref résumé statistique.\n\n\n\nVoir le code\n\n\nazote_ble &lt;- read.csv(\"azote_ble.csv\",row.names = 1)\nsummary(azote_ble)\n\n   Dose_Azote        Rendement    \n Min.   :  0.125   Min.   :1.600  \n 1st Qu.: 49.094   1st Qu.:4.571  \n Median : 94.128   Median :5.197  \n Mean   :101.073   Mean   :4.946  \n 3rd Qu.:153.179   3rd Qu.:5.554  \n Max.   :198.854   Max.   :6.352  \n\n\n\n\nUn modèle linéaire semble-t-il adapté afin d’expliquer le rendement des champs ?\n\n\n\nRéponse\n\nPour répondre à cette question, on va :\n\ntracer le nuage de points donnant le rendement dans un champ en fonction de la dose d’azote;\ncalculer le coefficient de corrélation entre les deux variables.\n\n\nlibrary(ggplot2)\n\nggplot(azote_ble) + aes(x=Dose_Azote,y=Rendement)+\n  geom_point(color=\"skyblue\")+\n  theme_minimal()+\n  labs(x=\"Dose d'azote (en kg/ha)\",\n       y=\"Rendement (en T/ha)\",\n       title = \"Rendement du champ en fonction de la dose d'azote\")\n\n\n\n\n\n\n\ncor.test(x=azote_ble$Dose_Azote,azote_ble$Rendement)\n\n\n    Pearson's product-moment correlation\n\ndata:  azote_ble$Dose_Azote and azote_ble$Rendement\nt = 4.4398, df = 90, p-value = 2.55e-05\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2398778 0.5784672\nsample estimates:\n    cor \n0.42387 \n\n\nIci, le coefficient de corrélation est significativement non nul. Néanmoins, la forme du nuage de points ne montre absolument pas de tendance linéaire, mais plutôt une tendance polynomiale.\nUn modèle linéaire ne semble donc pas adapté.\n\n\nOn se propose de modéliser le rendement des champs par un modèle polynomial de degré 4 :\n\n\\[ Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 +\\beta_4X^4+ \\varepsilon\\] où :\n\n\\(X\\) désigne la dose d’azote apportée (en kg/ha);\n\\(Y\\) désigne le rendement du champ (en T/ha);\n\\(\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)\\) désigne un bruit gausssien.\n\nModifier le jeu de données initial afin de faire apparaître les variables \\(X^2\\), \\(X^3\\) et \\(X^4\\).\n\n\nVoir le code\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.2\n✔ lubridate 1.9.4     ✔ tibble    3.3.0\n✔ purrr     1.1.0     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nazote_ble &lt;- azote_ble %&gt;%\n  mutate(Dose_Azote2 = Dose_Azote^2,\n         Dose_Azote3 = Dose_Azote^3,\n         Dose_Azote4 = Dose_Azote^4)\n\n\n\nÀ l’aide de la fonction lm(), ajuster un modèle polynomial aux données.\n\n\n\nVoir le code\n\n\nlm_ble &lt;- lm(data=azote_ble,formula = Rendement~.)\n\n\n\nQuel est le pourcentage de variance expliquée par le modèle ? Certains coefficients semblent-ils non significatifs ?\n\n\n\nRéponse\n\nOn dresse un résumé du modèle :\n\nsummary(lm_ble)\n\n\nCall:\nlm(formula = Rendement ~ ., data = azote_ble)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.78238 -0.24016  0.02354  0.17685  0.90809 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.954e+00  1.966e-01   9.940 5.36e-16 ***\nDose_Azote   8.039e-02  1.305e-02   6.163 2.17e-08 ***\nDose_Azote2 -3.752e-04  2.590e-04  -1.448    0.151    \nDose_Azote3 -9.330e-07  1.920e-06  -0.486    0.628    \nDose_Azote4  5.639e-09  4.729e-09   1.192    0.236    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3424 on 87 degrees of freedom\nMultiple R-squared:  0.8784,    Adjusted R-squared:  0.8728 \nF-statistic: 157.1 on 4 and 87 DF,  p-value: &lt; 2.2e-16\n\n\nIci, les coefficients associés aux puissances 2, 3 et 4 de la dose d’azote ne semblent, à première vue, pas significatifs. On va voir plus loin que ce n’est pas si clair…\n\n\nEffectuer un ou plusieurs tests de modèles emboîtés afin de déterminer les coefficients significativement non nuls du modèle. Quel modèle est finalement retenu ?\n\n\n\nRéponse\n\nOn va tout d’abord tester la nullité des coefficients \\(\\beta_2\\), \\(\\beta_3\\) et \\(\\beta_4\\) associés aux puissances 2, 3 et 4 de la dose d’azote.\n\nmod1 &lt;- lm(data=azote_ble,formula = Rendement~ Dose_Azote)\nanova(lm_ble,mod1)\n\nAnalysis of Variance Table\n\nModel 1: Rendement ~ Dose_Azote + Dose_Azote2 + Dose_Azote3 + Dose_Azote4\nModel 2: Rendement ~ Dose_Azote\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1     87 10.201                                  \n2     90 68.806 -3   -58.605 166.61 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nD’après ce test, au moins l’un des coefficients \\(\\beta_2, \\beta_3\\) ou \\(\\beta_4\\) est non nul. Pour déterminer lesquels, on va ensuite tester la nullité simultanée de \\(\\beta_3\\) et \\(\\beta_4\\).\n\nmod2 &lt;- lm(data=azote_ble,formula = Rendement~Dose_Azote + Dose_Azote2)\nsummary(mod2)\n\n\nCall:\nlm(formula = Rendement ~ Dose_Azote + Dose_Azote2, data = azote_ble)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.0291 -0.2481 -0.0511  0.2438  1.2901 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.381e+00  1.291e-01   18.44   &lt;2e-16 ***\nDose_Azote   6.130e-02  2.976e-03   20.60   &lt;2e-16 ***\nDose_Azote2 -2.684e-04  1.429e-05  -18.78   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3946 on 89 degrees of freedom\nMultiple R-squared:  0.8347,    Adjusted R-squared:  0.831 \nF-statistic: 224.8 on 2 and 89 DF,  p-value: &lt; 2.2e-16\n\nanova(lm_ble,mod2)\n\nAnalysis of Variance Table\n\nModel 1: Rendement ~ Dose_Azote + Dose_Azote2 + Dose_Azote3 + Dose_Azote4\nModel 2: Rendement ~ Dose_Azote + Dose_Azote2\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1     87 10.201                                  \n2     89 13.861 -2   -3.6599 15.607 1.614e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOn voit ici que le coefficient \\(\\beta_2\\) est significativement non nul. De plus, l’un des deux coefficients \\(\\beta_3\\) ou \\(\\beta_4\\) est aussi non nul. On va tester lequel.\n\nmod3&lt;- lm(data=azote_ble,formula=Rendement~Dose_Azote+\n            Dose_Azote2+Dose_Azote3)\nsummary(mod3)\n\n\nCall:\nlm(formula = Rendement ~ Dose_Azote + Dose_Azote2 + Dose_Azote3, \n    data = azote_ble)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.79733 -0.22234 -0.00154  0.17302  0.95400 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.808e+00  1.539e-01  11.746  &lt; 2e-16 ***\nDose_Azote   9.387e-02  6.518e-03  14.403  &lt; 2e-16 ***\nDose_Azote2 -6.708e-04  7.494e-05  -8.952 5.16e-14 ***\nDose_Azote3  1.338e-06  2.456e-07   5.445 4.63e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3432 on 88 degrees of freedom\nMultiple R-squared:  0.8764,    Adjusted R-squared:  0.8722 \nF-statistic:   208 on 3 and 88 DF,  p-value: &lt; 2.2e-16\n\nanova(lm_ble,mod3)\n\nAnalysis of Variance Table\n\nModel 1: Rendement ~ Dose_Azote + Dose_Azote2 + Dose_Azote3 + Dose_Azote4\nModel 2: Rendement ~ Dose_Azote + Dose_Azote2 + Dose_Azote3\n  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)\n1     87 10.201                           \n2     88 10.368 -1  -0.16667 1.4214 0.2364\n\n\nOn a enfin notre réponse : seul le coefficient \\(\\beta_4\\) n’est pas significativement non nul.\nFinalement, on retient le modèle \\[Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 +\\beta_3 X^3 + \\varepsilon.\\]\n\n\nTracer le nuage de points représentant les données, et y ajouter les différents intervalles de confiance au niveau 95% pour les prédictions faites par le modèle.\n\n\n\nVoir le code\n\n\n# On calcule les valeurs ajustées par le modèle et leur intervalle de prédiction\npred &lt;- predict(mod3,newdata = azote_ble,interval = \"prediction\") %&gt;%\n  as.data.frame()\n\n# Ici, on rajoute l'intervalle de confiance pour les valeurs moyennes des prévisions\npred_moy &lt;- predict(mod3,newdata = azote_ble,interval = \"confidence\") %&gt;%\n  as.data.frame()\n\nggplot(azote_ble)+aes(x=Dose_Azote,y=Rendement)+\n  geom_point()+\n  geom_line(aes(y=pred_moy$fit,linetype=\"Prévisions\"),\n            color=\"blue4\",lwd=1)+\n  geom_ribbon(aes(ymin = pred_moy$lwr,\n                  ymax=pred_moy$upr,\n                  fill=\"Intervalle de confiance pour les valeurs moyennes (95%)\"),\n              alpha=0.2)+\n  scale_fill_manual(values=\"blue2\")+\n  geom_line(aes(y=pred$lwr,\n                linetype=\"Intervalle de confiance pour les prévisions (95%)\"))+\n  geom_line(aes(y=pred$upr,\n                linetype=\"Intervalle de confiance pour les prévisions (95%)\"))+\n  scale_linetype_manual(values=c(\"dotted\",\"dashed\"))+\n  theme_minimal()+\n  theme(legend.position = \"bottom\",legend.title = element_blank(),\n        legend.box = \"vertical\")+\n  labs(title = \"Rendement d'un champ de blé en fonction de la dose d'azote\",\n       x=\"Dose d'azote (en kg/ha)\",\n       y= \"Rendement (en T/ha)\")\n\n\n\n\n\n\n\n\n\n\n\nExercice 2\nOn étudie dans cet exercice l’espérance de vie moyenne dans un pays en fonction de sa population et de son PIB par habitant. On dispose pour cela d’un jeu de données (disponible  ici ) libre de droits issu de la banque mondiale, et disponible sur Gapminder.org, CCBY License.\nOn trouvera dans ce jeu de données pour 142 pays en 2007 :\n\nle PIB par habitant;\nla population du pays;\nle continent du pays;\nl’espérance de vie dans le pays.\n\n\nImporter les données dans R et résumer brièvement les données.\n\n\n\nVoir le code\n\n\nlife_expectancy &lt;- read.csv(\"life_expectancy.csv\", row.names=1) %&gt;%\n  mutate(continent = as.factor(continent))\n\n\n\nAjuster un modèle linéaire permettant d’expliquer l’espérance de vie dans un pays en fonction des autres variables. Ecrire mathématiquement ce modèle.\n\n\n\nRéponse\n\nIci, la variable country n’est pas utilisée, car elle sert simplement à nommer chaque observation. La variable continent est, quant à elle, qualitative.\nOn note ci-dessous :\n\n\\(Y\\) la variable lifeExp (observations \\(y_1,\\ldots,y_n\\));\n\\(X_1\\) la variable continent (observations \\(x_{1,1},\\ldots,x_{n,1}\\));\n\\(X_2\\) la variable pop (observations \\(x_{1,2},\\ldots,x_{n,2}\\));\n\\(X_3\\) la variable gdpPercap (observations \\(x_{1,3},\\ldots,x_{n,3}\\)).\nLe modèle envisagé est donné pour tout \\(i \\in \\{1,\\ldots,n\\}\\) par \\[{\\small y_i = \\beta_0 + \\beta_1^{Americas} \\mathbf{1}_{Americas}(x_{i,1}) + \\beta_1^{Asia} \\mathbf{1}_{Asia}(x_{i,1}) +\\beta_1^{Europe}\\mathbf{1}_{Europe}(x_{i,1}) + \\beta_1^{Oceania} \\mathbf{1}_{Oceania}(x_{i,1}) + \\beta_2 x_{i,2} + \\beta_3 x_{i,3} + \\varepsilon_i }\\] où les \\(\\varepsilon_i\\) sont i.i.d. de loi \\(\\mathcal{N}(0,\\sigma^2)\\).\nRemarque : Le modèle ne contient ici pas de coefficient \\(\\beta_1^{Africa}\\) pour des raisons d’identifiabilité. En d’autres termes, si on intégrait ce coeffcient dans le modèle, différentes valeurs des coefficients aboutiraient aux mêmes valeurs réponses, ce qui poseraient un souci quant à la bonne définition du problème.\n\n\nlm_life &lt;- lm(data=life_expectancy,formula = lifeExp ~ continent + pop + gdpPercap)\n\n\n\nQuel le pourcentage de variance expliquée par ce modèle ?\n\n\n\nRéponse\n\n\nsummary(lm_life)\n\n\nCall:\nlm(formula = lifeExp ~ continent + pop + gdpPercap, data = life_expectancy)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.8199  -2.8905   0.1574   2.9046  20.0585 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       5.371e+01  9.356e-01  57.413  &lt; 2e-16 ***\ncontinentAmericas 1.603e+01  1.671e+00   9.592  &lt; 2e-16 ***\ncontinentAsia     1.256e+01  1.621e+00   7.751 1.97e-12 ***\ncontinentEurope   1.520e+01  1.966e+00   7.730 2.20e-12 ***\ncontinentOceania  1.662e+01  4.993e+00   3.329  0.00112 ** \npop               9.586e-10  3.926e-09   0.244  0.80747    \ngdpPercap         3.479e-04  5.717e-05   6.086 1.13e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.597 on 135 degrees of freedom\nMultiple R-squared:  0.7141,    Adjusted R-squared:  0.7014 \nF-statistic:  56.2 on 6 and 135 DF,  p-value: &lt; 2.2e-16\n\n\nCe modèle explique 71,41% de la variance.\n\n\nRé-ajuster le modèle afin de ne conserver que les coefficients significativement non nuls.\n\n\n\nRéponse\n\nIci, on ne supprime que la variable pop.\n\nlm_life_reduit &lt;- lm(data=life_expectancy,formula = lifeExp ~continent + gdpPercap)\nsummary(lm_life_reduit)\n\n\nCall:\nlm(formula = lifeExp ~ continent + gdpPercap, data = life_expectancy)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.9145  -2.8518   0.1407   2.8881  20.0479 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       5.374e+01  9.284e-01  57.881  &lt; 2e-16 ***\ncontinentAmericas 1.606e+01  1.662e+00   9.663  &lt; 2e-16 ***\ncontinentAsia     1.267e+01  1.557e+00   8.137 2.27e-13 ***\ncontinentEurope   1.523e+01  1.956e+00   7.786 1.57e-12 ***\ncontinentOceania  1.665e+01  4.974e+00   3.348  0.00105 ** \ngdpPercap         3.466e-04  5.674e-05   6.109 9.89e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.574 on 136 degrees of freedom\nMultiple R-squared:  0.714, Adjusted R-squared:  0.7035 \nF-statistic:  67.9 on 5 and 136 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nUn modèle linéaire n’est pas tout à fait adapté ici. On va utiliser un modèle non linéaire en utilisant une transformation logarithmique sur les données de PIB par habitant.\n\n\nEcrire mathématiquement le modèle considéré.\nCréer une nouvelle variable donnant le logarithme du PIB par habitant.\nReprésenter brièvement les nouvelles données obtenues.\nA l’aide de la fonction lm() ajuster le modèle envisagé aux données.\nQuel est le gain sur le coefficient de détermination ?\n\n\n\nRéponse\n\nLe modèle considéré ici est, en reprenant les notations précédentes \\[\\small{y_i = \\beta_0 + \\beta_1^{Americas} \\mathbf{1}_{Americas}(x_{i,1}) + \\beta_1^{Asia} \\mathbf{1}_{Asia}(x_{i,1}) +\\beta_1^{Europe}\\mathbf{1}_{Europe}(x_{i,1}) + \\beta_1^{Oceania} \\mathbf{1}_{Oceania}(x_{i,1}) + \\beta_3 \\ln( x_{i,3}) + \\varepsilon_i.}\\] Remarque : on rappelle que, dans un soucie de parcimonie, on n’a pas conservé la variable \\(X_2\\).\nOn transforme dorénavant les données et on les représente.\n\nlife_expectancy &lt;- life_expectancy %&gt;%\n  mutate(log_gdpPercap = log(gdpPercap))\nlibrary(GGally)\nggpairs(life_expectancy[,2:5])\n\n\n\n\n\n\n\n\nOn ajuste ensuite notre modèle.\n\nlm_life_log &lt;- lm(data=life_expectancy,formula = lifeExp~continent + log_gdpPercap)\nsummary(lm_life_log)\n\n\nCall:\nlm(formula = lifeExp ~ continent + log_gdpPercap, data = life_expectancy)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.4917  -2.3146  -0.0432   2.5498  14.8818 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        20.1376     4.0332   4.993 1.79e-06 ***\ncontinentAmericas  11.6942     1.6546   7.068 7.46e-11 ***\ncontinentAsia      10.1144     1.4761   6.852 2.31e-10 ***\ncontinentEurope    11.2682     1.8936   5.951 2.14e-08 ***\ncontinentOceania   12.9293     4.5211   2.860  0.00491 ** \nlog_gdpPercap       4.6308     0.5274   8.780 6.14e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.929 on 136 degrees of freedom\nMultiple R-squared:  0.7674,    Adjusted R-squared:  0.7588 \nF-statistic: 89.72 on 5 and 136 DF,  p-value: &lt; 2.2e-16\n\n\nOn voit ici que ce dernier modèle explique 5% de variance en plus que le précédent.\n\n\nOn souhaite dorénavant comparer les deux modèles construits.\n\n\nDans un premier temps, comparer les coefficients de détermination \\(R^2\\) et \\(R_a^2\\).\nOn compare ensuite les critères \\(AIC\\) (Akaike Information Criterion) des deux modèles : \\[AIC = 2p-2\\ln(L)\\] où\n\n\n\\(p\\) désigne le nombre de paramètres à estimer dans le modèle;\n\\(L\\) désigne la vraisemblance du modèle.\n\nUn tel critère vise à pénaliser les modèles ayant trop de paramètres à estimer. Il favorise donc les modèles parcimonieux en sélectionnant le modèle avec le critère \\(AIC\\) le plus faible.\nSélectionner le modèle ayant le meilleur critère \\(AIC\\) à l’aide de la fonction AIC().\n\nOn compare dorénavant les critères \\(BIC\\) (Bayesian Information Criterion) des modèles : \\[BIC = p\\ln(n) -2\\ln(L)\\] où \\(n\\) désigne le nombre d’observations. Une nouvelle fois, le but est de choisir un modèle parcimonieux en sélectionnant le critère \\(BIC\\) le plus faible. Comparé au critère \\(AIC\\), le critère \\(BIC\\) pénalise plus fortement les modèles avec beaucoup de paramètres à estimer.\n\nSélectionner le modèle ayant le meilleur critère \\(BIC\\), à l’aide de la fonction BIC().\n\nEnfin, on compare les performances prédictives des modèles. Pour ce faire, on va estimer le risque quadratique des deux modèles par validation croisée 10 blocs (voir TD2).\n\nSélectionner le modèle semblant avoir la meilleure performance prédictive.\n\n\nRéponse\n\n\nComparons les \\(R^2\\) et \\(R_a^2\\) :\n\n\nsummary(lm_life_reduit)\n\n\nCall:\nlm(formula = lifeExp ~ continent + gdpPercap, data = life_expectancy)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-22.9145  -2.8518   0.1407   2.8881  20.0479 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       5.374e+01  9.284e-01  57.881  &lt; 2e-16 ***\ncontinentAmericas 1.606e+01  1.662e+00   9.663  &lt; 2e-16 ***\ncontinentAsia     1.267e+01  1.557e+00   8.137 2.27e-13 ***\ncontinentEurope   1.523e+01  1.956e+00   7.786 1.57e-12 ***\ncontinentOceania  1.665e+01  4.974e+00   3.348  0.00105 ** \ngdpPercap         3.466e-04  5.674e-05   6.109 9.89e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.574 on 136 degrees of freedom\nMultiple R-squared:  0.714, Adjusted R-squared:  0.7035 \nF-statistic:  67.9 on 5 and 136 DF,  p-value: &lt; 2.2e-16\n\nsummary(lm_life_log)\n\n\nCall:\nlm(formula = lifeExp ~ continent + log_gdpPercap, data = life_expectancy)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.4917  -2.3146  -0.0432   2.5498  14.8818 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        20.1376     4.0332   4.993 1.79e-06 ***\ncontinentAmericas  11.6942     1.6546   7.068 7.46e-11 ***\ncontinentAsia      10.1144     1.4761   6.852 2.31e-10 ***\ncontinentEurope    11.2682     1.8936   5.951 2.14e-08 ***\ncontinentOceania   12.9293     4.5211   2.860  0.00491 ** \nlog_gdpPercap       4.6308     0.5274   8.780 6.14e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.929 on 136 degrees of freedom\nMultiple R-squared:  0.7674,    Adjusted R-squared:  0.7588 \nF-statistic: 89.72 on 5 and 136 DF,  p-value: &lt; 2.2e-16\n\n\nLe modèle avec la transformation logarithmique possède à la fois un meilleur \\(R^2\\) et un meilleur \\(R_a^2\\).\n\nComparons ensuite les AIC :\n\n\nAIC(lm_life_reduit)\n\n[1] 945.6641\n\nAIC(lm_life_log)\n\n[1] 916.3339\n\n\nUne fois encore, selon le critère AIC, on sélectionnerait le modèle logarithmique.\n\nMaintenant, comparons les BIC :\n\n\nBIC(lm_life_reduit)\n\n[1] 966.3549\n\nBIC(lm_life_log)\n\n[1] 937.0247\n\n\nOn a toujours la même conclusion.\n\nComparons enfin les performances prédictives des deux modèles via une validation croisée 10 blocs :\n\n\nlibrary(tidymodels)\nset.seed(333)\n\n# Création des 10 blocs\nfolds &lt;- vfold_cv(data=life_expectancy,v = 10) \n\n# Spécification du modèle linéaire utilisé\nlm_spec &lt;- linear_reg(mode=\"regression\",engine=\"lm\")\n\n# Précision des modèles utilisés dans un workflow\nlm_workflow1 &lt;- workflow() %&gt;% add_model(lm_spec) %&gt;% add_formula(lifeExp~continent + gdpPercap)\n\nlm_workflow2 &lt;- workflow() %&gt;% add_model(lm_spec) %&gt;% add_formula(lifeExp~continent + log_gdpPercap)\n\n# Ajustement du modèle pour chaque bloc\nlm_cv1 &lt;- lm_workflow1 %&gt;% fit_resamples(resamples = folds)\nlm_cv2 &lt;- lm_workflow2 %&gt;% fit_resamples(resamples = folds)\n\n# Récupération des métriques d'évaluation obtenues par validation croisée\nmetrics_lm_cv1 &lt;- collect_metrics(lm_cv1)\nmetrics_lm_cv2 &lt;- collect_metrics(lm_cv2)\nmetrics_lm_cv1\n\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   6.31     10  0.677  pre0_mod0_post0\n2 rsq     standard   0.729    10  0.0494 pre0_mod0_post0\n\nmetrics_lm_cv2\n\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   5.81     10  0.474  pre0_mod0_post0\n2 rsq     standard   0.777    10  0.0280 pre0_mod0_post0\n\n\nLe modèle logarithmique possède une meilleure capacité prédictive. Il bat donc le modèle linéaire à tout point de vue.",
    "crumbs": [
      "TD3 : Régression non linéaire"
    ]
  },
  {
    "objectID": "TD1.html",
    "href": "TD1.html",
    "title": "TD1 : Régression linéaire simple",
    "section": "",
    "text": "Exercice 1\nOn considère le jeu de données tomato_sauce.csv disponible  ici .\nLes données recueillies portent sur des mesures effectuées sur un site de production de sauce à base de tomate.\nLa variable \\(Y\\) à expliquer, notée rdt, est une réponse liée au rendement de production (% d’extrait de tomate dans la sauce).\nLa variable explicative \\(X\\), notée ratioMP, est relative à la qualité du lot de matières premières (% de solides insolubles dans l’eau par rapport à la quantité de solide totale).\n24 observations ont été réalisées sur une série d’ordres de production consécutifs\n\nImporter les données dans R, et en dresser un rapide résumé statistique.\n\n\n\nVoir le code\n\n\ntomato_sauce &lt;- read.csv(\"tomato_sauce.csv\",sep=\";\",row.names=1)\nsummary(tomato_sauce)\n\n    ratioMP           rdt       \n Min.   :10.71   Min.   :30.20  \n 1st Qu.:12.67   1st Qu.:35.88  \n Median :13.70   Median :39.10  \n Mean   :13.78   Mean   :39.73  \n 3rd Qu.:14.82   3rd Qu.:43.38  \n Max.   :18.22   Max.   :51.00  \n\n\n\n\nRéaliser les boxplots et histogrammes des différentes variables. Commenter.\n\n\n\nVoir le code\n\n\nlibrary(ggplot2)\n\n# Boxplots\nggplot(tomato_sauce) + aes(x=\"\",y=ratioMP)+\n  geom_boxplot(width=0.1)+\n  theme_minimal()+\n  labs(title=\"Distribution de la variable ratioMP\",x=\"\")\n\n\n\n\n\n\n\n# On remarque une valeur anormalement grande\nggplot(tomato_sauce) + aes(x=\"\",y=rdt)+\n  geom_boxplot(width=0.1)+\n  theme_minimal()+\n  labs(title=\"Distribution de la variable rdt\",x=\"\")\n\n\n\n\n\n\n\n# Rien à signaler\n\n# Histogrammes\nn &lt;- nrow(tomato_sauce) # nombre d'observations\nn_class &lt;- ceiling(1+3.3*log10(n)) #nombre de classes (Formule de Sturges)\n\nggplot(tomato_sauce)+ aes(x=ratioMP)+\n  geom_histogram(fill=\"skyblue\",color=\"grey40\",bins=n_class)+\n  theme_minimal()+\n  labs(title=\"Distribution de la variable ratioMP\",y=\"Effectifs\")\n\n\n\n\n\n\n\n# Il y a un cerrtain nombre de valeurs très basses, les autres étant globalement regroupées autour de la moyenne\nggplot(tomato_sauce)+ aes(x=rdt)+\n  geom_histogram(fill=\"skyblue\",color=\"grey40\",bins=n_class)+\n  theme_minimal()+\n  labs(title=\"Distribution de la variable rdt\",y=\"Effectifs\")\n\n\n\n\n\n\n\n# Les données semblent regroupées en 2 paquets : un autour de 37, l'autre, plus petit, autour de 45\n\n\n\nTracer le nuage de points associé aux données, puis calculer le coefficient de corrélation linéaire entre les deux variables (rappeler la définition de ce dernier).\n\n\n\nCommentaire\n\nPour deux séries d’observations \\((x_i)_{1\\leqslant i \\leqslant n}\\) et \\((y_i)_{1\\leqslant i \\leqslant n}\\), le coefficient de corrélation est donné par \\[\\rho = \\dfrac{\\sum_{i=1}^n (x_i -\\overline{x})(y_i-\\overline{y})}{\\sqrt{\\sum_{i=1}^n (x_i-\\overline{x})^2}\\times \\sqrt{\\sum_{i=1}^n (y_i-\\overline{y})^2}}\\]\n\n\n\nVoir le code\n\n\nggplot(tomato_sauce) + aes(x=ratioMP,y=rdt)+\n  geom_point(color=\"tomato\")+\n  theme_minimal()+\n  labs(title=\"Nuage de points rdt VS ratioMP\")\n\n\n\n\n\n\n\ncor.test(x=tomato_sauce$ratioMP,y=tomato_sauce$rdt)\n\n\n    Pearson's product-moment correlation\n\ndata:  tomato_sauce$ratioMP and tomato_sauce$rdt\nt = -18.718, df = 22, p-value = 5.293e-15\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9871402 -0.9308572\nsample estimates:\n       cor \n-0.9700104 \n\n\n\nCelui-ci est-il significativement non nul ? Un modèle linéaire semble-t-il adapté aux données ? Ecrire mathématiquement ce modèle.\n\n\nRéponse\n\nLe test statistique réalisé nous renvoie une \\(p\\)-value inférieure à 0.05 (elle est égale à \\(5.293\\times 10^{-15}\\)). On rejette donc l’hypothèse nulle comme quoi les deux séries sont non corrélées. En d’autres termes, le coefficient de corrélation est siginificativement non nul. Un modèle linéaire semble alors parfaitement adapté aux données (tendance linéaire sur le nuage de points + coefficient de corrélation significativement non nul). Celui-ci s’écrit \\[ rdt_i = \\beta_0 + \\beta_1 ratioMP_i + \\varepsilon_i, \\quad 1 \\leqslant i  \\leqslant n,\\] où les \\(\\varepsilon_i\\) sont i.i.d. de loi \\(\\mathcal{N}(0,\\sigma^2)\\).\n\n\nÀ l’aide de la fonction lm(), ajsuter un modèle linéaire aux données. En faire un résumé rapide avec la fonction summary().\n\n\n\nVoir le code\n\n\nlm_sauce &lt;- lm(data=tomato_sauce,formula = rdt~.)\nsummary(lm_sauce)\n\n\nCall:\nlm(formula = rdt ~ ., data = tomato_sauce)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.5871 -0.9040 -0.1434  1.0381  3.1522 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  76.1934     1.9657   38.76  &lt; 2e-16 ***\nratioMP      -2.6467     0.1414  -18.72 5.29e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.288 on 22 degrees of freedom\nMultiple R-squared:  0.9409,    Adjusted R-squared:  0.9382 \nF-statistic: 350.4 on 1 and 22 DF,  p-value: 5.293e-15\n\n\n\n\nDonner les valeurs estimées des coefficients du modèle, ainsi qu’un intervalle de confiance à 95% de ces coefficients avec la fonction confint(). Ceux-ci sont-ils significativement non nuls ? Préciser la statistique de test utilisée ici.\n\n\n\nRéponse\n\nOn a les estimations \\[\\hat{\\beta}_0 \\approx 76.1934 \\quad \\text{et} \\quad \\hat{\\beta}_1 \\approx -2.6467.\\] Ceux-ci sont significativement non nuls (présence de 3 étoiles dans le résumé). La statistique de test utilisée ici est, pour \\(i \\in \\{0,1\\}\\) \\[t_i = \\dfrac{\\hat{\\beta}_i}{\\hat{\\sigma}_i} \\] qui suit la loi de Student \\(\\mathcal{T}_{n-2}\\) sous l’hypothèse nulle \\(H_0 : \\beta_i=0\\). Les intervalles de confiance des coefficients sont donnés par le code ci-dessous.\n\n\n\nVoir le code\n\n\nconfint(lm_sauce)\n\n                2.5 %    97.5 %\n(Intercept) 72.116805 80.270061\nratioMP     -2.939885 -2.353422\n\n\n\n\nQuelle est la proportion de variance expliquée par le modèle ? Rappeler la définition de l’indicateur statistique utilisé.\n\n\n\nRéponse\n\nOn utilise le coefficient de déterminations \\(R^2\\) \\[ R^2 = \\dfrac{SCE}{SCT} = \\dfrac{\\sum_{i=1}^n (\\hat{y}_i-\\overline{y})^2}{\\sum_{i=1}^n (y_i-\\overline{y})^2}\\] où les \\(\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_i\\) sont les valeurs ajustées par le modèle. Ici, on a \\(R^2 \\approx 0.9409\\), ce qui signifie que le modèle explique 94,09% de la variance. Il est donc extrêmement bien adapté aux données.\n\n\nUtiliser la fonction geom_smooth() du package ggplot2 afin de tracer la droite de régression linéaire ajustée aux données.\n\nL’intervalle de confiance à 95% tracé par cette fonction est celui de la valeur \\(\\hat{\\beta}_0 + \\hat{\\beta}_1 x\\). Il s’agit en fait de l’intervalle de confiance pour la valeur moyenne de la variable réponse \\(y\\).\n\n\nVoir le code\n\n\nggplot(tomato_sauce) + aes(x=ratioMP,y=rdt)+\n  geom_point(color=\"tomato\")+\n  geom_smooth(method=\"lm\",color=\"tomato\",linetype=\"dashed\",lwd=0.5,fill=\"tomato\",alpha=0.2)+\n  theme_minimal()+\n  labs(title = \"rdt VS ratioMP\")\n\n\n\n\n\n\n\n\n\n\nOn souhaite à présent rajouter l’intervalle de confiance pour les prévisions faites par le modèle. Celui-ci est différent de l’intervalle tracé par la fonction geom_smooth(). Il prend notamment en compte la dispersion liée au bruit gaussien du modèle.\n\n\nA l’aide de la fonction predict() récupérer les bornes inférieures et supérieures des prévisions associées aux observations du jeu de données. On stockera ces valeurs dans le data-frame initial avec pour noms de variables pred_lwr et pred_upr.\nRajouter, à l’aide de la fonction geom_line(), ces bornes sur le graphique réalisé jusqu’à présent.\n\n\n\nVoir le code\n\n\nlibrary(tidyverse)\npred &lt;- predict(lm_sauce,newdata = tomato_sauce,interval=\"prediction\")\n\ntomato_sauce &lt;- tomato_sauce %&gt;%\n  mutate(pred_lwr = pred[,2],\n         pred_upr = pred[,3])\n\nggplot(tomato_sauce) + aes(x=ratioMP,y=rdt)+\n  geom_point(color=\"tomato\")+\n  geom_smooth(method=\"lm\",linetype=\"dashed\",lwd=0.5,color=\"tomato\",alpha=0.2,\n              aes(fill=\"Intervalle de confiance pour la valeur moyenne (95%)\"))+\n  scale_fill_manual(values=\"tomato\")+\n  theme_minimal()+\n  labs(title = \"rdt VS ratioMP\")+\n  geom_line(aes(y=pred_lwr,linetype=\"Intervalle de confiance pour les prévisions (95%)\"))+\n  geom_line(aes(y=pred_upr,linetype=\"Intervalle de confiance pour les prévisions (95%)\"))+\n  scale_linetype_manual(values=\"dotted\")+\n  theme(legend.title = element_blank(),\n        legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n\nExercice 2\nOn s’intéresse ici à l’équilibre des saveurs dans différents cidres.\n90 cidres bruts ont été évalués par un jury sensoriel formé de 24 juges (échelle de notation de 1 à 10, calcul des notes moyennes), selon différents critères :\n\nSaveur sucrée;\nSaveur Acide;\nSaveur amère;\nSaveur astringente\n\nOn étudie plus précisément la relation entre la saveur astringente (variable réponse) des cidres et leur saveur amère (variable explicative).\n\nImporter le jeu de données dans R (disponible  ici ), et en dresser un rapide résumé statistique.\n\n\n\nVoir le code\n\n\ncidre &lt;- read.csv(\"cidre.csv\",row.names = 1)\nsummary(cidre)\n\n    S.Sucree        S.Acide         S.Amere      S.Astringente   \n Min.   :3.444   Min.   :2.107   Min.   :2.143   Min.   :0.7143  \n 1st Qu.:4.580   1st Qu.:3.625   1st Qu.:3.286   1st Qu.:1.4732  \n Median :5.250   Median :4.089   Median :3.964   Median :2.0000  \n Mean   :5.169   Mean   :4.181   Mean   :4.274   Mean   :2.0561  \n 3rd Qu.:5.670   3rd Qu.:4.643   3rd Qu.:5.268   3rd Qu.:2.4286  \n Max.   :7.036   Max.   :6.536   Max.   :7.857   Max.   :4.6786  \n                                                 NA's   :4       \n\nsum(is.na(cidre))\n\n[1] 4\n\n# Attention, il y a 4 valeurs manquantes pour la saveur Astringente...\n\n\n\nReprésenter graphiquement la distribution des différentes variables du jeu de données par la méthode de votre choix.\n\n\n\nVoir le code\n\n\n# On se propose ici de faire des boxplots\nggplot(cidre) + aes(x=\"\",y=S.Sucree)+\n  geom_boxplot(width=0.1)+\n  theme_minimal()+\n  labs(x=\"\",\n       y=\"Saveur sucrée\",\n       title = \"Distribution des notes pour la saveur sucrée\")\n\n\n\n\n\n\n\nggplot(cidre) + aes(x=\"\",y=S.Acide)+\n  geom_boxplot(width=0.1)+\n  theme_minimal()+\n  labs(x=\"\",\n       y=\"Saveur sucrée\",\n       title = \"Distribution des notes pour la saveur acide\")\n\n\n\n\n\n\n\nggplot(cidre) + aes(x=\"\",y=S.Amere)+\n  geom_boxplot(width=0.1)+\n  theme_minimal()+\n  labs(x=\"\",\n       y=\"Saveur sucrée\",\n       title = \"Distribution des notes pour la saveur amère\")\n\n\n\n\n\n\n\nggplot(cidre) + aes(x=\"\",y=S.Astringente)+\n  geom_boxplot(width=0.1)+\n  theme_minimal()+\n  labs(x=\"\",\n       y=\"Saveur sucrée\",\n       title = \"Distribution des notes pour la saveur astringente\")\n\n\n\n\n\n\n\n# On remarque quelques outliers pour les saveurs acide et astringente\n\n\n\nCombien de données manquantes le jeu de données comporte-t-il ?\n\n\n\nRéponse\n\nComme indiqué plus haut, il y en a quatre.\n\n\nOn souhaite imputer ces valeurs manquantes via un modèle linéaire simple reliant la saveur astringente (variable réponse) des cidre et leur saveur amère (variable explicative).\n\nUn tel modèle vous semble-t-il adapté ?\n\n\nRéponse\n\nOn va réaliser un nuage de points de ces deux variables, et calculer leur coefficient de corrélation.\n\nggplot(cidre) + aes(x=S.Amere,y=S.Astringente)+\n  geom_point(color=\"tomato\")+\n  theme_minimal()+\n  labs(title=\"Saveur astringente en fonction de la saveur amère\",\n       x=\"Note de saveur amère\",\n       y=\"Note de saveur astringente\")\n\n\n\n\n\n\n\ncor.test(x=cidre$S.Amere,y=cidre$S.Astringente)\n\n\n    Pearson's product-moment correlation\n\ndata:  cidre$S.Amere and cidre$S.Astringente\nt = 13.583, df = 84, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7485333 0.8853255\nsample estimates:\n     cor \n0.828942 \n\n\nEtant donné la forme du nuage de points et la significativité du coefficient de corrélation (\\(p\\)-value inférieure à \\(2.2\\times 10^{-16}\\) dans le test de nullité), un modèle linéaire semble parfaiement adapté aux données.\n\n\nAjuster un modèle linéaire donnant la saveur astringente en fonction de la saveur amère. Quel est le pourcentage de variance expliquée par ce modèle ?\n\n\n\nVoir le code\n\n\nlm_cidre &lt;- lm(data=cidre,formula = S.Astringente~S.Amere)\nsummary(lm_cidre)\n\n\nCall:\nlm(formula = S.Astringente ~ S.Amere, data = cidre)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.14284 -0.32774 -0.05057  0.27225  1.60204 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.14678    0.16938  -0.867    0.389    \nS.Amere      0.50964    0.03752  13.583   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4532 on 84 degrees of freedom\n  (4 observations effacées parce que manquantes)\nMultiple R-squared:  0.6871,    Adjusted R-squared:  0.6834 \nF-statistic: 184.5 on 1 and 84 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\nRéponse\n\nLe pourcentage de variance expliquée par ce modèle est de 68,71%.\n\n\nSur un graphique, représenter :\n\n\nle nuage de points donnant la saveur astringente des cidres en fonction de leur saveur amère;\nla droite de régression linéaire donnée par le modèle utilisé;\nles différents intervalles de confiance au niveau 95% pour les prévisions faites par le modèle.\n\n\n\nVoir le code\n\n\npred &lt;- predict(lm_cidre,newdata = cidre,interval=\"prediction\")\ncidre &lt;- cidre %&gt;%\n  mutate(pred_lwr=pred[,2],\n         pred_upr=pred[,3])\n\nggplot(cidre)+aes(x=S.Amere,y=S.Astringente)+\n  geom_point(color=\"tomato\")+\n  geom_smooth(method=\"lm\",color=\"tomato\",lwd=0.5,linetype=\"dashed\",alpha=0.2,\n              aes(fill=\"Intervalle de confiance pour la valeur moyenne (95%)\"))+\n  scale_fill_manual(values=\"tomato\")+\n  geom_line(aes(y=pred_lwr,linetype = \"Intervalle de confiance pour les prévisions (95%)\"))+\n  geom_line(aes(y=pred_upr,linetype = \"Intervalle de confiance pour les prévisions (95%)\"))+\n  scale_linetype_manual(values=\"dotted\")+\n  theme_minimal()+\n  labs(title = \"Saveur astringente en fonction de la saveur amère\",\n       x=\"Note de aveur amère\",\n       y=\"Note de saveur astringente\")+\n  theme(legend.position = \"bottom\",\n        legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\nImputer enfin les valeurs manquantes, et donner leur intervalle de confiance au niveau 95%.\n\n\n\nVoir le code\n\n\nvalues_to_impute &lt;- cidre %&gt;%\n  filter(is.na(S.Astringente))\nimputed_values &lt;- predict(lm_cidre,newdata = values_to_impute,interval = \"prediction\")\nimputed_values\n\n       fit       lwr      upr\n1 1.363927 0.4517479 2.276105\n2 1.491336 0.5810406 2.401631\n3 1.855363 0.9483536 2.762371\n4 1.309323 0.3962213 2.222424",
    "crumbs": [
      "TD1 : Régression linéaire simple"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EC651 et 56/53 : Modélisation statistique (Régression linéaire)",
    "section": "",
    "text": "Avant-Propos\nCe notebook contient les exercices liés à la première partie du cours de modélisation statistique, concernant la régression linéaire.\nVous trouverez, sur la barre de navigation à gauche, le menu vous permettant d’accéder aux différents TDs.\nVous trouverez ci-dessous des liens utiles pour ce cours et ces TDS :\n\nLes slides de cours;\nLe polycopié d’Arnaud Guyader;\nLe lien vers le site du livre R pour la statistique et la science des données, sous la direction de F.Husson.",
    "crumbs": [
      "Avant-Propos"
    ]
  },
  {
    "objectID": "TD2.html",
    "href": "TD2.html",
    "title": "TD2 : Régression linéaire multiple",
    "section": "",
    "text": "Exercice 1\nOn considère un échantillon de 500 produits anti-âge disponible  ici .\nLe jeu de données consiste en 6 variables :\n\nproduct_type,\nviscosity en mPa.s,\npH,\ndensity en g/cm\\(^3\\),\nsurface_tension en mN/m,\nuser_rating, correspondant à une note moyenne donnée par les consommateurs (entre 1 et 5).\n\nOn cherche à expliquer la note donnée par les consommateurs en fonction des autres variables.\n\nImporter les données dans R et effectuer un rapide résumé statistique.\n\n\n\nVoir le code\n\n\ncosmetics &lt;- read.csv(\"cosmetics.csv\",row.names=1)\nlibrary(tidyverse)\ncosmetics &lt;- cosmetics %&gt;%\n  mutate(product_type=as.factor(product_type)) # On met cette variable en facteur\nsummary(cosmetics)\n\n product_type   viscosity            pH           density       surface_tension\n cream :122   Min.   : 534.9   Min.   :4.620   Min.   :0.9180   Min.   :26.20  \n gel   :122   1st Qu.: 893.0   1st Qu.:5.515   1st Qu.:0.9577   1st Qu.:33.10  \n lotion:108   Median :1290.8   Median :5.900   Median :0.9950   Median :36.20  \n serum :148   Mean   :1711.8   Mean   :5.881   Mean   :0.9905   Mean   :37.30  \n              3rd Qu.:1826.4   3rd Qu.:6.240   3rd Qu.:1.0180   3rd Qu.:41.23  \n              Max.   :4104.0   Max.   :7.020   Max.   :1.0590   Max.   :53.30  \n  user_rating   \n Min.   :2.490  \n 1st Qu.:3.170  \n Median :3.415  \n Mean   :3.481  \n 3rd Qu.:3.763  \n Max.   :4.760  \n\n\n\n\nReprésenter graphiquement les liens pouvant exister entre la variable user_rating et les autres.\n\n\n\nVoir le code\n\n\nlibrary(GGally)\n\nggpairs(cosmetics[,2:6])\n\n\n\n\n\n\n\n\n\n\n\nCommentaire\n\nBien que les corrélations calculées entre les différentes variables soient significativement non nuls, les nuages de points ne montrent pas de tendance particulière, si ce n’est entre les variables user_rating et surface_tension. On remarque toutefois des clusters sur certains nuages de points, notamment pour la variable viscosity, montrant l’impact de la variable catégorielle product_type, indiquant si le produit est une crème, un gel, etc…\n\n\nUn modèle linéaire semble-t-il adapté pour prédire la note donnée par les consommateurs ? Ecrire mathématiquement ce modèle.\n\n\n\nRéponse\n\nD’après la significativité des coefficients de corrélation, on peut penser qu’un modèle linéaire est adapté aux données. On fera toutefois attention au fait que les variables explicatives sont parfois fortement corrélées entre elles. Etant donné la présence d’une variable qualitative (product_type), celui-ci s’écrit un peu différemment. On note :\n\n\\(Y\\) la variable réponse user_rating, (observations \\(y_1,\\ldots,y_n\\));\n\\(X_1\\) la variable product_type, (observations \\(x_{1,1},\\ldots,x_{n,1}\\));\n\\(X_2\\) la variable viscosity, (observations \\(x_{1,2},\\ldots,x_{n,2}\\));\n\\(X_3\\) la variable pH, (observations \\(x_{1,3},\\ldots,x_{n,3}\\));\n\\(X_4\\) la variable density, (observations \\(x_{1,4},\\ldots,x_{n,4}\\));\n\\(X_5\\) la variable surface_tension, (observations \\(x_{1,5},\\ldots,x_{n,5}\\)).\n\nOn a alors pour tout \\(i \\in \\{1,\\ldots,n\\}\\) \\[y_i = \\beta_0 + \\beta_1^{gel} \\mathbf{1}_{gel}(x_{i,1}) + \\beta_1^{lotion} \\mathbf{1}_{lotion}(x_i,1) +\\beta_1^{serum} \\mathbf{1}_{serum}(x_{i,1}) + \\beta_2 x_{i,2} + \\beta_3 x_{i,3} +\\beta_4 x_{i,4} + \\beta_5 x_{i,5} + \\varepsilon_i\\] où les \\(\\varepsilon_i\\) son i.i.d. de loi \\(\\mathcal{N}(0,\\sigma^2)\\).\nRemarque : Le modèle ne contient ici pas de coefficient \\(\\beta_1^{cream}\\) pour des raisons d’identifiabilité. En d’autres termes, si on intégrait ce coeffcient dans le modèle, différentes valeurs des coefficients aboutiraient aux mêmes valeurs réponses, ce qui poseraient un souci quant à la bonne définition du problème.\n\n\nAjuster un modèle linéaire aux données, permettant d’expliquer user_rating en fonction des autres variables.\n\n\n\nVoir le code\n\n\nlm_cosmetics &lt;- lm(data=cosmetics,formula = user_rating~.)\nsummary(lm_cosmetics)\n\n\nCall:\nlm(formula = user_rating ~ ., data = cosmetics)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.80811 -0.20967  0.01328  0.19511  0.93520 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         3.037e+00  9.844e-01   3.085  0.00215 ** \nproduct_typegel     1.238e-01  1.965e-01   0.630  0.52905    \nproduct_typelotion  4.285e-02  1.621e-01   0.264  0.79161    \nproduct_typeserum   9.843e-02  2.168e-01   0.454  0.65001    \nviscosity           2.848e-04  7.241e-05   3.933  9.6e-05 ***\npH                 -1.651e-01  6.498e-02  -2.542  0.01134 *  \ndensity             6.947e-01  8.555e-01   0.812  0.41714    \nsurface_tension     4.606e-03  5.795e-03   0.795  0.42706    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2916 on 492 degrees of freedom\nMultiple R-squared:  0.5926,    Adjusted R-squared:  0.5868 \nF-statistic: 102.2 on 7 and 492 DF,  p-value: &lt; 2.2e-16\n\n\n\nQuel est le pourcentage de variance expliquée par le modèle ?\nQuelles variables ne semblent pas expliquer la note donnée par les consommateurs ?\n\n\nRéponse\n\n\nLe coefficient \\(R^2\\) calculé est de 0.5926. Le modèle explique donc 59,26% de la variance.\nLes variables ayant un coefficient non significatif sont les suivantes :\n\nproduct_type;\ndensity;\nsurface_tension.\n\n\nElles ne semblent donc pas expliquer la note donnée par les consommateurs.\n\n\nÀ l’aide de la fonction anova(), réaliser un test de modèles emboîtés afin de déterminer les variables intervenant réellement dans le modèle. Ecrire les hypothèses envisagées dans ce test.\n\n\n\nRéponse\n\nD’après le résumé statistique effectué précédemment, on envisage le test \\[ H_0 : \\beta_1^{gel}=\\beta_1^{lotion} = \\beta_1^{serum}=\\beta_4=\\beta_5=0 \\quad \\text{contre} \\quad H_1 : \\text{l'un de ces coeffcients est non nul.} \\] On rappelle que la statistique de test utilisée ici est \\[ F = \\dfrac{n-p}{q} \\times \\dfrac{SCR_0 - SCR}{SCR}, \\] qui suit une loi de Fisher \\(\\mathcal{F}_{n-p}^q\\) sous \\(H_0\\), où\n\n\\(p\\) est le nombre de paramètres à estimer dans le modèle complet;\n\\(q\\) est la différence du nombre de paramètres à estimer entre le modèle complet et le modèle réduit;\n\\(SCR\\) est la somme des carrés résiduelle dans le modèle complet;\n\\(SCR_0\\) est la somme des carrés résiduelle dans le modèle réduit.\n\n\n\n\nVoir le code\n\n\nlm_cosmetics_reduit &lt;- lm(data=cosmetics,formula = user_rating ~  viscosity + pH)\nanova(lm_cosmetics,lm_cosmetics_reduit)\n\nAnalysis of Variance Table\n\nModel 1: user_rating ~ product_type + viscosity + pH + density + surface_tension\nModel 2: user_rating ~ viscosity + pH\n  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)\n1    492 41.825                           \n2    497 42.157 -5  -0.33217 0.7815 0.5633\n\n# Avec une p-value de 0.5633, one ne rejette pas l'hypothèse nulle H0.\n\n\n\nOn souhaite maintenant comparer les performances prédictitives des deux modèles utilisés précédemment :\n\n\nle modèle complet, avec toutes les variables;\nle modèle réduit, comprenant uniquement les variables semblant expliquer la note donnée par les consommateurs.\n\nPour ce faire, on dispose de 50 données supplémentaires (disponibles  ici ).\nPrédire, avec les deux modèles, les notes données par les consommateurs pour ces 50 nouveaux produits.\n\n\nVoir le code\n\n\ncosmetics_extra &lt;- read.csv(\"cosmetics_extra.csv\",row.names=1)%&gt;%\n  mutate(product_type=as.factor(product_type))\npred_complet &lt;- predict(lm_cosmetics,newdata = cosmetics_extra)\npred_reduit &lt;- predict(lm_cosmetics_reduit, newdata = cosmetics_extra)\n\n\n\nCalculer, pour chacune des prédictions, l’erreur quadratique moyenne \\(MSE\\) réalisée par chaque modèle : \\[ MSE = \\dfrac{1}{50} \\sum_{i=1}^{50} (y_i - \\hat{y}_i)^2 \\]\n\n\n\nVoir le code\n\n\nMSE_complet &lt;- mean((cosmetics$user_rating-pred_complet)^2)\nMSE_reduit &lt;- mean((cosmetics$user_rating-pred_reduit)^2)\nMSE_complet\n\n[1] 0.3117702\n\nMSE_reduit\n\n[1] 0.3133974\n\n\n\nQuel modèle semble avoir la meileure performance prédictive ? Comparer avec les coefficients de détermination \\(R^2\\) obtenus par chacun des modèles.\n\n\nRéponse\n\nAvec un \\(MSE\\) inférieur, le modèle complet réalise moins d’erreur sur la prédiction de nouvelles données, bien que certaines des variables utilisées n’aient a priori pas d’impact sur la note d’un produit.\n\n\n\nExercice 2\nOn considère ici les données présentées dans les slides de cours sur le rendement de 80 champs de tomates, disponibles  ici .\n\nImporter les données dans R et effectuer un rapide résumé statistique. Représenter par un graphique simple les données.\n\n\n\nVoir le code\n\n\nchamps_tomates &lt;- read.csv(\"champs_tomates.csv\",row.names=1)\nggpairs(champs_tomates)\n\n\n\n\n\n\n\n\n\n\nAjuster un modèle linéaire aux données. Quel est le pourcentage de variance expliquée par le modèle ?\n\n\n\nVoir le code\n\n\nlm_tomates &lt;- lm(data=champs_tomates,formula = Rendement~.)\nsummary(lm_tomates)\n\n\nCall:\nlm(formula = Rendement ~ ., data = champs_tomates)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.249633 -0.046002 -0.000089  0.061775  0.233529 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    2.1283588  0.2857600   7.448 1.42e-10 ***\nEngrais        0.0013818  0.0004776   2.894 0.005001 ** \nIrrigation     0.0082729  0.0040953   2.020 0.046994 *  \nHeures_Travail 0.0021900  0.0031519   0.695 0.489337    \nQualite_Sol    0.0041781  0.0011842   3.528 0.000723 ***\nTemperature    0.0180394  0.0115351   1.564 0.122114    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1016 on 74 degrees of freedom\nMultiple R-squared:  0.3499,    Adjusted R-squared:  0.306 \nF-statistic: 7.965 on 5 and 74 DF,  p-value: 4.767e-06\n\n# Le modèle explique 34,99% de la variance.\n\n\n\nQuels coefficients de la régression ne semblent pas significatifs ? Préciser la statistique de test utilisée.\n\n\n\nRéponse\n\nPour chaque coefficient \\(\\beta_i\\), on effectue le test \\[H_0 : \\beta_i = 0 \\quad \\text{contre} \\quad H_1 : \\beta_i \\neq0.\\] Sous \\(H_0\\), on a \\(t_i = \\dfrac{\\hat{\\beta}_i}{\\hat{\\sigma}_i} \\sim \\mathcal{T}_{n-p}\\), où \\(p\\) est le nombre de paramètres à estimer. On rejette \\(H_0\\) au seuil \\(\\alpha\\) si \\(|t_i| &gt; t_{n-p}(1-\\alpha/2)\\) le quantile d’ordre \\(1-\\alpha/2\\) de la loi \\(\\mathcal{T}_{n-p}\\).\nIci, les coefficients associés aux variables Heures_Travail et Temperature ne sont pas signifcativeùent non nuls.\n\n\nRéaliser un test de modèles emboîtés afin de tester la nullité simultanée de ces coefficients. Quel est la statistique de test utilisée ici ?\n\n\n\nRéponse\n\nOn teste ici \\[H_0 : \\beta_3 = \\beta_5 = 0 \\quad \\text{contre} \\quad H_1: \\beta_3\\neq 0 \\ \\text{ou} \\ \\beta_5 \\neq 0. \\] Sous \\(H_0\\), la statistique de test \\[ F = \\dfrac{n-p}{2}\\times \\dfrac{SCR_0-SCR}{SCR}\\] suit la loi de Fisher \\(\\mathcal{F}_{n-p}^2\\), où\n\n\\(SCR\\) est la somme des carrés résiduelle quand on prend toutes les variables dans le modèle;\n\\(SCR_0\\) est la somme des carrés résiduelles quand on ne prend pas les variables Heures_Travail et Temperature dans le modèle.\n\n\nlm_tomates_reduit &lt;- lm(data=champs_tomates,formula = Rendement~Engrais + Irrigation + Qualite_Sol)\nanova(lm_tomates,lm_tomates_reduit)\n\nAnalysis of Variance Table\n\nModel 1: Rendement ~ Engrais + Irrigation + Heures_Travail + Qualite_Sol + \n    Temperature\nModel 2: Rendement ~ Engrais + Irrigation + Qualite_Sol\n  Res.Df     RSS Df Sum of Sq      F Pr(&gt;F)\n1     74 0.76409                           \n2     76 0.79376 -2 -0.029669 1.4367 0.2443\n\n\nIci, on ne rejette pas l’hypothèse nulle (\\(p\\)-value égale à 0.2443).\n\n\nComme dans l’exercice précédent, on souhaite comparer la capacité prédictive des deux modèles construits.\n\nPour ce faire, on propose d’utiliser une validation croisée 10 blocs. Le principe est de séparer aléatoirement le jeu de données en 10 blocs de 8 observations, et d’ajuster 10 fois le modèle linéaire avec les variables retenues. Pour chacun des 10 ajustements :\n\n9 blocs (72 observations) servent à entraîner le modèle;\n1 bloc (8 observations) sert à prédire les nouvelles valeurs, et calculer le \\(MSE\\) sur 8 valeurs;\non estime enfin le risque quadratique du modèle en calculant la moyenne des 10 \\(MSE\\) calculés.\n\nOn présente ci-dessous un code utilisant le package tidymodels permettant d’effectuer cette validation croisée pour le modèle complet.\n\nlibrary(tidymodels)\nset.seed(42)\n\n# Création des 10 blocs\nfolds &lt;- vfold_cv(data=df_tomato,v = 10) \n\n# Spécification du modèle linéaire utilisé\nlm_spec &lt;- linear_reg(mode=\"regression\",engine=\"lm\")\n\n# Précision du modèle utilisé dans un workflow\nlm_workflow &lt;- workflow() %&gt;% add_model(lm_spec) %&gt;% add_formula(Rendement~.)\n\n# Ajustement du modèle pour chaque bloc\nlm_cv &lt;- lm_workflow %&gt;% fit_resamples(resamples = folds)\n\n# Récupération des métriques d'évaluation obtenues par validation croisée\nmetrics_lm_cv &lt;- collect_metrics(lm_cv)\nmetrics_lm_cv\n\nAdapter ce code au problème de l’exercice, et comparer les performances prédictives du modèle complet et du modèle réduit.\n\n\nRéponse\n\nOn effectue une validation croisée pour chaque modèle. Pour le modèle complet, on a :\n\nlibrary(tidymodels)\nset.seed(42)\n\n# Création des 10 blocs\nfolds &lt;- vfold_cv(data=champs_tomates,v = 10) \n\n# Spécification du modèle linéaire utilisé\nlm_spec &lt;- linear_reg(mode=\"regression\",engine=\"lm\")\n\n# Précision du modèle utilisé dans un workflow\nlm_workflow_complet &lt;- workflow() %&gt;% add_model(lm_spec) %&gt;% add_formula(Rendement~.)\n\n# Ajustement du modèle pour chaque bloc\nlm_cv_complet &lt;- lm_workflow_complet %&gt;% fit_resamples(resamples = folds)\n\n# Récupération des métriques d'évaluation obtenues par validation croisée\nmetrics_lm_cv_complet &lt;- collect_metrics(lm_cv_complet)\n\nEt pour le modèle réduit :\n\n# Précision du modèle utilisé dans un workflow\nlm_workflow_reduit &lt;- workflow() %&gt;% add_model(lm_spec) %&gt;% \n  add_formula(Rendement~Engrais + Irrigation + Qualite_Sol)\n\n# Ajustement du modèle pour chaque bloc\nlm_cv_reduit &lt;- lm_workflow_reduit %&gt;% fit_resamples(resamples = folds)\n\n# Récupération des métriques d'évaluation obtenues par validation croisée\nmetrics_lm_cv_reduit &lt;- collect_metrics(lm_cv_reduit)\n\nOn compare ensuite les \\(RMSE\\), qui sont les racines carrées des \\(MSE\\) définis plus haut.\n\nmetrics_lm_cv_complet\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   0.0990    10  0.0120 pre0_mod0_post0\n2 rsq     standard   0.416     10  0.0783 pre0_mod0_post0\n\nmetrics_lm_cv_reduit\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   0.0983    10  0.0118 pre0_mod0_post0\n2 rsq     standard   0.412     10  0.0807 pre0_mod0_post0\n\n\nLe modèle réduit semble ainsi légèrement plus performant que le modèle complet pour effectuer des pévisions.",
    "crumbs": [
      "TD2 : Régression linéaire multiple"
    ]
  }
]